{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집개요\n",
    "\n",
    "## 데이터 선정\n",
    "\n",
    "- 요구사항 분석을 통해 분석목표가 정해졌다면 어떤 데이터를 수집할지 선정해야 한다.\n",
    "    - 수집 대상 데이터는 그 목적과 직접적 관련이 있는 데이터과 간접적 관련이 있는 데이터가 있다.\n",
    "    - 예: 축구 승리에 미치는 영향을 주는 요인들\n",
    "        - **축구와 직접 관련된 데이터(요인)**\n",
    "            - 축구 기록 관련: 골, 득점 기대수치, 볼 점유율, 패스 성공율, 슈팅 시도, 태클 시도 및 성공등\n",
    "            - 선수 관련: 연봉, 나이, 경력, 최근 경기 성적등\n",
    "            - 기타: 홈 원정 여부, 경기 시작 시간, 최근 5경기 결과, 직전 경기 결과 등\n",
    "        - **간접 관련된 데이터(요인)**\n",
    "            - 경기 당일 날씨\n",
    "            - 관중수, 응원단 수\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 방법 선정\n",
    "- 수집할 데이터를 선정했다면 그 다음은 어떻게 데이터를 수집할지 그 방법을 정해야 한다.\n",
    "- **어디서 구할 것인가?**\n",
    "    - 사내 데이터베이스\n",
    "    - 외부 데이터\n",
    "        - 외부 데이터일 경우 어디서 구할 수 있는지 조사해야한다.\n",
    "            - 공개 데이터셋\n",
    "            - 유료 데이터셋\n",
    "            - 데이터 크롤링(crawling)\n",
    "                - 크롤링시 법적 문제는 없는지 확인해야 한다.\n",
    "- **수집할 데이터의 양은 충분한지 확인**\n",
    "    - 의미 있는 결과를 얻으려면 다양한 패턴의 데이터를 의미 있는 양만큼 수집해야 한다.\n",
    "    - 수집 데이터가 한쪽에 편향 되지 않아야 한다. \n",
    "        - 스팸메일을 분석하기 위한 데이터를 수집할 때 정상메일이 스팸메일보다 훨씬 만다면?\n",
    "        - 지하철 호선별 평균이용량을 수집하는데 1호선은 7월, 2호선은 2월, 3호선은 12월 같이 다른 기준으로 데이터를 수집한다면?\n",
    "- **수집할 데이터가 신뢰할만 한 데이터인지 확인 필요**\n",
    "    - 4차산업혁명, 인터넷, SNS 발달로 데이터의 양이 급증가하여 데이터 수집이 쉬워짐.\n",
    "    - 쉬어진 만큼 신뢰하기 힘든 데이터들도 급증함. 그래서 **수집한 데이터가 신뢰할 만한 데이터인지 구별하는 것이 중요해졌다.**\n",
    "        - 특히 출처가 불분명한 데이터 (커뮤니티 글, 유튜브 영상, 지식IN 등)일 경우 확인이 필요함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 주기\n",
    "- 일회성인지 주기적으로 수집해야 하는 데이터인지에 따라 방법과 도구가 달라질 수 있다.\n",
    "- **일회성 데이터**\n",
    "    - 수집한 데이터를 csv, txt등의 파일형식으로 저장하여 활용한다.\n",
    "    - 변하지 않는 데이터셋으로 국가나 도시정보등이 있다.\n",
    "- **주기적으로 수집이 필요한 데이터**\n",
    "    - 자동화 시스템 구축을 하여 데이터베이스에 데이터를 주기적으로 수집, 저장한다.\n",
    "    - 변하는 데이터로 대부분이 여기에 속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집에 도움이 되는 사이트\n",
    "\n",
    "- **국가 통계포털**\n",
    "    - https://kosis.kr\n",
    "    - 통계청에서 관리하는 공공데이터 포털로 다양한 카테고리의 국가 통계데이터를 제공한다.\n",
    "\n",
    "- **공공데이터 포털**\n",
    "    - https://www.data.go.kr\n",
    "    - 행정 안전부에서 제공하는 정부 데이터 포털\n",
    "- **Kaggle**\n",
    "    - https://kaggle.com\n",
    "    - 데이터과학 관련 경진대회 플랫폼\n",
    "    - 다양한 데이터들을 제공한다.\n",
    "- **구글 데이터셋 서치**\n",
    "    - https://datasetsearch.research.google.com\n",
    "    - 구글에서 제공하는 데이터셋 검색 사이트\n",
    "    - 키워드를 이용해 다양한 데이터셋을 검색하고 다운로드 받을 수 있다.\n",
    "- **AI Hub**\n",
    "    - https://aihub.or.kr\n",
    "    - 국내외 기관/기업에서 추진한 지능정보산업 인프라 조성사업에서 공개한 AI 학습용 데이터셋들을 제공한다.\n",
    "- **Roboflow Universe**\n",
    "    - https://universe.roboflow.com/\n",
    "    - Roboflow 라는 인공지능 회사에서 운영하는 데이터 저장소 사이트로 컴퓨터비전 관련 데이터셋을 주로 제공한다.\n",
    "- 기타\n",
    "    - **지자체**: 서울시 열린 데이터광장, 경기 데이터 드림\n",
    "    - **금융관련**: 한국거래소, 금융통계정보시스템등\n",
    "    - **영화관련**: 영화진흥위원회\n",
    "    - **대중교통**: 국가교통데이터베이스, 교통카드 빅데이터 통합정보시스템등    \n",
    "    - **관광관련**: 한국 관광 데이터랩등\n",
    "    - **날씨정보**: 기상청 기상자료 개방포털, 네이버 날씨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [크롬개발자 도구](https://developers.google.com/web/tools/chrome-devtools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- Markup 언어 parsing 라이브러리\n",
    "    - HTML이나 XML 문서 내에서 원하는 정보를 가져오기 위한 파이썬 라이브러리.\n",
    "- https://www.crummy.com/software/BeautifulSoup/\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- 설치\n",
    "    - conda install beautifulsoup4\n",
    "    - pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코딩 패턴\n",
    "1. 조회할 HTML내용을 전달하여 BeautifulSoup 객체 생성 \n",
    "1. BeautifulSoup객체의 메소드들을 이용해 문서내에서 필요한 정보 조회\n",
    "    - 태그이름과 태그 속성으로 조회\n",
    "    - css selector를 이용해 조회\n",
    "    - . 표기법을 이용한 탐색(Tree 구조 순서대로 탐색)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 객체 생성\n",
    "- BeautifulSoup(html str [, 파서])\n",
    "    - 매개변수\n",
    "        1. 정보를 조회할 html을 string으로 전달\n",
    "        2. 파서\n",
    "            - html.parser(기본파서)\n",
    "            - lxml : 매우 빠르다. html, xml 파싱 가능(xml 파싱은 lxml만 가능)\n",
    "                - 사용시 install 필요 \n",
    "                - `conda install lxml`\n",
    "                - `pip install lxml`\n",
    "                - install 후 커널 restart 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "bs4.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HTML 문서를 읽어온다.\n",
    "with open(r'.\\testfiles\\example.html', 'rt', encoding='utf-8') as f:\n",
    "    html_f = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://grandpark.seoul.go.kr/main/ko.do'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beautifulsoup 객체 생성, 읽어온 html 문서를 파싱한다.\n",
    "soup_html = bs(html_f, 'lxml')\n",
    "\n",
    "\n",
    "animals = soup_html.find_all(class_='animal')\n",
    "counts = soup_html.find_all(class_='count')\n",
    "\n",
    "links = soup_html.find_all(id='link')\n",
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서내에서 원하는 정보 검색\n",
    "\n",
    "### Tag 객체\n",
    "- 하나의 태그(element)에 대한 정보를 다루는 객체.\n",
    "    - BeautifulSoup 조회 메소드들의 **조회결과의 반환타입.**\n",
    "    - 조회 함수들이 찾은 Element가 하나일 경우 **Tag 객체를, 여러개일 경우 Tag 객체들을 담은 List(ResultSet)**를 반환한다.\n",
    "    - Tag 객체는 찾은 정보를 제공하는 메소드와 Attribute를 가지고 있다. 또 찾은 Tag가 하위 element를 가질 경우 찾을 수 있는 조회 메소드를 제공한다.\n",
    "- 주요 속성/메소드\n",
    "    - **태그의 속성값 조회**\n",
    "        - tag객체.get('속성명') \n",
    "        - tag객체\\['속성명'\\]\n",
    "        - ex) tag.get('href') 또는 tag\\['href'\\]\n",
    "    - **태그내 text값 조회**\n",
    "        - tag객체.get_text()\n",
    "        - tag객체.text\n",
    "        - ex) tag.get_text() 또는 tag.text\n",
    "    - **contents 속성**\n",
    "        - 조회한 태그의 모든 자식 요소들을 리스트로 반환\n",
    "        - ex) child_list = tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .표기법을 사용하면 태그의 하위 객체를 조회할 수 있다.\n",
    "# 태그는 하위 객체들을 가지고 있다.\n",
    "# 태그는 트리 구조로 이루어져 있다.\n",
    "# 루트 노드는 html 태그이다.\n",
    "soup_html.html.head.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>\n",
      "https://grandpark.seoul.go.kr/main/ko.do\n",
      "https://grandpark.seoul.go.kr/main/ko.do\n",
      "서울대공원\n",
      "서울대공원\n"
     ]
    }
   ],
   "source": [
    "# 태그 객체\n",
    "tag1 = soup_html.find('a')\n",
    "\n",
    "# 태그 객체의 속성\n",
    "print(tag1)\n",
    "# get() 메소드를 사용하면 속성값을 가져올 수 있다.\n",
    "print(tag1.get('href'))\n",
    "# 딕셔너리 형태로도 속성을 가져올 수 있다.\n",
    "print(tag1['href'])\n",
    "# get_text() 메소드를 사용하면 태그의 텍스트를 가져올 수 있다.\n",
    "print(tag1.get_text())\n",
    "# 태그의 텍스트를 조회하는 다른 방법\n",
    "print(tag1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조회 함수\n",
    "- **태그의 이름으로 조회**\n",
    "    - find_all()\n",
    "    - find()\n",
    "- **css selector를 이용해 조회**\n",
    "    - select(), select_one()\n",
    "- **`.` 표기법(dot notation)**\n",
    "    - dom tree 구조의 계층 순서대로 조회\n",
    "    - 위의 두방식으로 찾은 tag를 기준으로 그 주위의 element 들을 찾을 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>,\n",
       " <a href=\"https://www.everland.com/web/everland/main.html\" id=\"link\">에버랜드 동물원</a>,\n",
       " <a href=\"https://www.coexaqua.com/\" id=\"link\">코엑스 아쿠아리움</a>,\n",
       " <a href=\"https://www.naver.com\" id=\"link\">네이버</a>,\n",
       " <a href=\"https://www.google.co.kr\" id=\"link\">구글</a>,\n",
       " <a href=\"https://www.w3schools.com\" id=\"link\">HTML 배우기</a>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_all() 함수를 사용하여 원하는 태그를 찾는다.\n",
    "# find_all() 함수는 태그 객체들을 담은 리스트 형태로 반환한다.\n",
    "soup_html.find_all('a', id='link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find() 함수는 태그 객체를 반환한다.\n",
    "soup_html.find('a', id='link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태그의 이름으로 조회\n",
    "- **find_all**(name=태그명, attrs={속성명:속성값, ..})\n",
    "   - 이름의 모든 태그 element들을 리스트에 담아 반환.\n",
    "   - 여러 이름의 태그를 조회할 경우 List에 태그명들을 묶어서 전달한다.\n",
    "   - 태그의 attribute 조건으로만 조회할 경우 name을 생략한다. \n",
    "- **find**(name=태그명, attrs={속성명:속성값})\n",
    "    - 이름의 태그중 첫번째 태그 element를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>, <a href=\"https://www.everland.com/web/everland/main.html\" id=\"link\">에버랜드 동물원</a>, <a href=\"https://www.coexaqua.com/\" id=\"link\">코엑스 아쿠아리움</a>, <a href=\"https://www.naver.com\" id=\"link\">네이버</a>, <a href=\"https://www.google.co.kr\" id=\"link\">구글</a>, <a href=\"https://www.w3schools.com\" id=\"link\">HTML 배우기</a>]\n"
     ]
    }
   ],
   "source": [
    "# a 태그를 모두 찾는다.\n",
    "result1 = soup_html.find_all('a')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"animal\">기린</span>, <a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>, <a href=\"https://www.everland.com/web/everland/main.html\" id=\"link\">에버랜드 동물원</a>, <a href=\"https://www.coexaqua.com/\" id=\"link\">코엑스 아쿠아리움</a>, <a href=\"https://www.naver.com\" id=\"link\">네이버</a>, <a href=\"https://www.google.co.kr\" id=\"link\">구글</a>, <a href=\"https://www.w3schools.com\" id=\"link\">HTML 배우기</a>]\n"
     ]
    }
   ],
   "source": [
    "# a, span 태그를 모두 찾는다.\n",
    "result2 = soup_html.find_all(['a', 'span'])\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"animal\">사자</div>, <div class=\"animal\">호랑이</div>, <div class=\"animal\">사슴</div>, <div class=\"animal\">곰</div>]\n"
     ]
    }
   ],
   "source": [
    "# # animal 클래스를 가진 div 태그를 찾는다.\n",
    "result3 = soup_html.find_all('div', class_='animal')\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"animal\">사자</div>, <div class=\"animal\">호랑이</div>, <div class=\"animal\">사슴</div>, <div class=\"animal\">곰</div>, <span class=\"animal\">기린</span>]\n"
     ]
    }
   ],
   "source": [
    "# animal 클래스를 가진 태그를 찾는다.\n",
    "result4 = soup_html.find_all(attrs={'class':'animal'})\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://www.naver.com\" id=\"link\">네이버</a>]\n",
      "<a href=\"https://www.naver.com\" id=\"link\">네이버</a>\n"
     ]
    }
   ],
   "source": [
    "# herf 속성이 http://www.naver.com인 a 태그를 찾는다.\n",
    "result5 = soup_html.find_all('a', {'href' : 'https://www.naver.com'}) \n",
    "print(result5)\n",
    "\n",
    "# 검색 결과가 하나임에도 리스트로 반환된다.\n",
    "# 검색결과가 하나인 경우 find() 함수를 사용하는 것이 좋다.\n",
    "result5 = soup_html.find('a', {'href' : 'https://www.naver.com'})\n",
    "print(result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://grandpark.seoul.go.kr/main/ko.do\" id=\"link\">서울대공원</a>, <a href=\"https://www.everland.com/web/everland/main.html\" id=\"link\">에버랜드 동물원</a>, <a href=\"https://www.coexaqua.com/\" id=\"link\">코엑스 아쿠아리움</a>, <a href=\"https://www.naver.com\" id=\"link\">네이버</a>, <a href=\"https://www.google.co.kr\" id=\"link\">구글</a>, <a href=\"https://www.w3schools.com\" id=\"link\">HTML 배우기</a>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# herf 속성이 https://로 시작하는 a 태그를 찾는다.\n",
    "# 정규표현식을 사용하여 검색할 수 있다.\n",
    "result6 = soup_html.find_all('a', {'href':re.compile('^https://')}) \n",
    "print(result6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "사자\n",
      "3마리\n",
      "\n",
      "['\\n', <div class=\"animal\">사자</div>, '\\n', <div class=\"count\">3마리</div>, '\\n']\n",
      "<div class=\"animal\">사자</div>\n",
      "<div class=\"count\">3마리</div>\n",
      "animal1\n"
     ]
    }
   ],
   "source": [
    "result = soup_html.find('div')\n",
    "print(result.text)  # 태그의 텍스트를 반환한다.\n",
    "print(result.contents)  # 태그의 자식 태그들을 리스트로 반환한다. 엔터도 포함된다.\n",
    "for t in result.contents:\n",
    "    if isinstance(t, bs4.element.Tag): # Tag 객체인지 확인한다.\n",
    "        print(t)\n",
    "        \n",
    "t = result.get('id') # 태그의 속성을 가져온다.\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Selector를 이용해 조회\n",
    "- **select(selector='css셀렉터')**\n",
    "    - css 셀렉터와 일치하는 tag들을 반환한다.\n",
    "- **select_one(selector='css셀렉터')**\n",
    "    - css 셀렉터와 일치하는 tag를 반환한다.\n",
    "    - 일치하는 것이 여러개일 경우 첫번째 것 하나만 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(soup_html.select(selector='animal1')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HTML 문서를 읽어온다.\n",
    "with open(r'.\\testfiles\\exam2.html', 'rt', encoding='utf-8') as f:\n",
    "    html_f = f.read()\n",
    "    \n",
    "soup = bs(html_f, 'lxml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 태그명으로 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://grandpark.seoul.go.kr/main/ko.do\">서울대공원</a>,\n",
       " <a href=\"https://www.everland.com/web/everland/favorite/zootopia/index.html\">에버랜드 동물원</a>,\n",
       " <a href=\"https://www.coexaqua.com\">코엑스 아쿠아리움</a>,\n",
       " <a href=\"https://www.google.co.kr\">구 글</a>,\n",
       " <a href=\"https://www.w3schools.com\">HTML배우기</a>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = soup.select('a')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"animal\">기린</span>,\n",
       " <a href=\"https://grandpark.seoul.go.kr/main/ko.do\">서울대공원</a>,\n",
       " <a href=\"https://www.everland.com/web/everland/favorite/zootopia/index.html\">에버랜드 동물원</a>,\n",
       " <a href=\"https://www.coexaqua.com\">코엑스 아쿠아리움</a>,\n",
       " <a href=\"https://www.google.co.kr\">구 글</a>,\n",
       " <a href=\"https://www.w3schools.com\">HTML배우기</a>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = soup.select('span, a')\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스명으로 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .속성값을 사용하여 태그를 검색할 수 있다.\n",
    "# 태그명.속성값 형태로 사용하면, 태그중에 해당 속성값을 가진 태그를 검색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"animal\">사자</div>,\n",
       " <div class=\"animal\">호랑이</div>,\n",
       " <div class=\"animal\">곰</div>,\n",
       " <span class=\"animal\">기린</span>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = soup.select('.animal')\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id 속성명으로 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #id속성값을 사용하여 태그를 검색할 수 있다.\n",
    "# 태그명#id속성값 형태로 사용하면, 태그중에 해당 id속성값을 가진 태그를 검색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"animal1\">\n",
       " <div class=\"animal\">사자</div>\n",
       " <div class=\"count\">3마리</div>\n",
       " </div>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = soup.select('#animal1')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"animal1\">\n",
       "<div class=\"animal\">사자</div>\n",
       "<div class=\"count\">3마리</div>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select() 함수는 리스트 형태로 반환한다.\n",
    "# id는 고유한 값이므로, 검색결과가 하나이다.\n",
    "# 이러한 경우에는 select_one() 함수를 사용하면 된다.\n",
    "result = soup.select_one('#animal1')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"animal\">사자</div>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parent > child\n",
    "# 자식 태그(노드)를 검색한다.\n",
    "result = soup.select('#animal1 > .animal')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://grandpark.seoul.go.kr/main/ko.do\">서울대공원</a>,\n",
       " <a href=\"https://www.everland.com/web/everland/favorite/zootopia/index.html\">에버랜드 동물원</a>,\n",
       " <a href=\"https://www.coexaqua.com\">코엑스 아쿠아리움</a>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조상에서 자손검색\n",
    "# 조상태그 (띄어쓰기) 자손태그\n",
    "result = soup.select('ul a')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
