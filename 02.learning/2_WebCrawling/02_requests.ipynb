{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# requests 모듈을 이용한 웹 요청\n",
    "- [Requests 홈페이지](https://requests.kennethreitz.org/en/master/)\n",
    "- **HTTP 요청을 처리하는 파이썬 패키지**\n",
    "- get/post 방식 모두를 지원하며 쿠키, 헤더정보등을 HTTP의 다양한 요청처리를 지원한다.\n",
    "- 설치\n",
    "    - `pip install requests`\n",
    "    - `conda install -c conda-forge requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling을 위한 requests 코딩 패턴\n",
    "1. requests의 get()/post() 함수를 이용해 url을 넣어 서버 요청한다.\n",
    "3. 응답받은 내용을 처리.\n",
    "    - text(HTML)은 BeautifulSoup에 넣어 parsing\n",
    "    - binary 파일의 경우 파일출력을 이용해 local에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 요청 함수\n",
    "- get(): GET방식 요청\n",
    "- post(): POST방식 요청"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### requests.get(URL)\n",
    "- **GET 방식 요청**\n",
    "- **주요 매개변수**\n",
    "    - params: 요청파라미터를 dictionary로 전달\n",
    "    - headers: HTTP 요청 header를 dictionary로 전달\n",
    "        - 'User-Agent', 'Referer' 등 헤더 설정\n",
    "    - cookies: 쿠키정보를 전달\n",
    "- **반환값(Return Value)**\n",
    "    - [Response](#Response객체): 응답결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests.post(URL)\n",
    "- **POST 방식 요청**\n",
    "- **주요 매개변수**\n",
    "    - datas : 요청파라미터를 dictionary로 전달\n",
    "    - files : 업로드할 파일을 dictionary로 전달\n",
    "        - key: 이름, value: 파일과 연결된 InputStream(TextIOWrapper)\n",
    "    - headers: HTTP 요청 header를 dictionary로 전달\n",
    "        - 'User-Agent', 'Referer' 등 헤더 설정\n",
    "    - cookies: 쿠키정보를 전달\n",
    "- **반환값(Return Value)**\n",
    "    - [Response](#Response객체): 응답결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ### 요청파라미터(Request Parameter)\n",
    "> - 요청파라미터란?\n",
    ">     - 서버가 일하기 위해 클라이언트로 부터 받아야하는 값들\n",
    ">     - `name=value` 형태이며 여러개일 경우 `&`로 연결해서 전송됨\n",
    "> - Get 요청시 queryString 으로 전달\n",
    ">     - querystring : URL 뒤에 붙여서 전송한다.\n",
    ">     - ex) https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=python\n",
    ">     - requests.get() 요청시 \n",
    ">         1. url 뒤에 querystring으로 붙여서 전송\n",
    ">         2. dictionary 에 name=value 형태로 만들어 매개변수 params에 전달\n",
    "> - Post 요청시 요청정보의 body에 넣어 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### HTTP 요청 헤더(Request Header)\n",
    "> HTTP 요청시 웹브라우저가 client의 여러 부가적인 정보들을 Key-Value 쌍 형식으로 전달한다.\n",
    "> - accept: 클라이언트가 처리가능한 content 타입 (Mime-type 형식으로 전달)\n",
    "> - accept-language: 클라이언트가 지원하는 언어(ex: ko, en-US)\n",
    "> - host: 요청한 host \n",
    "> - user-agent: 웹브라우저 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Response객체 -  응답데이터\n",
    "- get()/post() 의 요청에 대한 서버의 응답 결과를 Response에 담아 반환\n",
    "    - Response의 속성을 이용해 응답결과를 조회\n",
    "- 주요 속성(Attribut)\n",
    "    - **url**\n",
    "        - 응답 받은(요청한) url \n",
    "    - **status_code**\n",
    "        - HTTP 응답 상태코드\n",
    "    - **headers**\n",
    "        - 응답 header 정보를 dictionary로 반환\n",
    "- **응답 결과 조회**\n",
    "    - **text**\n",
    "        - 응답내용(html을 str로 반환)\n",
    "    - **content**\n",
    "        - 응답내용(응답결과가 binary-image, 동영상등- 일 경우사용하며 bytes로 반환)\n",
    "    - **json()**\n",
    "        - 응답 결과가 JSON 인 경우 dictionary로 변환해서 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = r'https://www.naver.com/'\n",
    "\n",
    "res = requests.get(url)\n",
    "print(type(res.text))\n",
    "soup = bs(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### JSON(JavaScript Object Notation)\n",
    "> key-value 형태 또는 배열 형태의 text이며 이 기종간 데이터 교환에 많이 사용된다. 자바스크립트 언어에서 Object와 array를 생성하는 문법을 이용해 만듬. \n",
    "- [JSON 공식사이트](http://json.org)\n",
    ">\n",
    "> ### json 모듈\n",
    "> JSON 형식 문자열을 다루는 모듈\n",
    "> - json.loads(json문자열)\n",
    ">    - JSON 형식 문자열을 dictionary로 변환\n",
    "> - json.dumps(dictionary)\n",
    ">    - dictionary를 JSON 형식 문자열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### HTTP 응답 상태코드\n",
    "> - https://developer.mozilla.org/ko/docs/Web/HTTP/Status \n",
    "- 2XX: 성공\n",
    "    - 200: OK\n",
    "- 3XX: 다른 주소로 이동 (이사)\n",
    "    - 300번대이면 자동으로 이동해 준다. 크롤링시는 볼일이 별로 없다.\n",
    "- 4XX: 클라이언트 오류 (사용자가 잘못한 것)\n",
    "  - 404: 존재하지 않는 주소\n",
    "- 5XX: 서버 오류 (서버에서 문제생긴 것)\n",
    "  - 500: 서버가 처리방법을 모르는 오류\n",
    "  - 503: 서버가 다운 등의 문제로 서비스 불가 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 방식 요청 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<class 'dict'>\n",
      "{'args': {},\n",
      " 'headers': {'Accept': '*/*',\n",
      "             'Accept-Encoding': 'gzip, deflate, br',\n",
      "             'Host': 'httpbin.org',\n",
      "             'User-Agent': 'python-requests/2.28.1',\n",
      "             'X-Amzn-Trace-Id': 'Root=1-643ce7d8-439ea8851527a06679999173'},\n",
      " 'origin': '222.112.208.66',\n",
      " 'url': 'http://httpbin.org/get'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "\n",
    "base_url = r'http://httpbin.org/{}'\n",
    "\n",
    "url = base_url.format('get')\n",
    "url\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "if response.status_code == 200:\n",
    "    # print(response.text)\n",
    "    txt = response.json()\n",
    "    print(type(txt))\n",
    "    pprint(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상태코드 : 200\n",
      "<class 'dict'>\n",
      "{'args': {'address': '서울시 강남구', 'age': '20', 'name': '홍길동'},\n",
      " 'headers': {'Accept': '*/*',\n",
      "             'Accept-Encoding': 'gzip, deflate, br',\n",
      "             'Host': 'httpbin.org',\n",
      "             'User-Agent': 'python-requests/2.28.1',\n",
      "             'X-Amzn-Trace-Id': 'Root=1-643ce98d-3817e6b42bb57ce2741a1f3b'},\n",
      " 'origin': '222.112.208.66',\n",
      " 'url': 'http://httpbin.org/get?name=홍길동&age=20&address=서울시+강남구'}\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 전달\n",
    "# 전달할 파라미터를 딕셔너리 형태로 만들어서 params 인자에 전달\n",
    "req_param = {\n",
    "    'name' : '홍길동',\n",
    "    'age' : 20,\n",
    "    'address' : '서울시 강남구'\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=req_param)\n",
    "\n",
    "print(f'상태코드 : {response.status_code}')\n",
    "if response.status_code == 200:\n",
    "    # print(response.text)\n",
    "    txt = response.json()\n",
    "    print(type(txt))\n",
    "    pprint(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상태코드 : 200\n",
      "<class 'dict'>\n",
      "{'args': {'address': '서울시 강남구', 'age': '20', 'name': '홍길동'},\n",
      " 'headers': {'Accept': '*/*',\n",
      "             'Accept-Encoding': 'gzip, deflate, br',\n",
      "             'Host': 'httpbin.org',\n",
      "             'My-Header': 'my_value',\n",
      "             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
      "                           'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
      "                           'Chrome/114.0.0.0 Safari/537.36',\n",
      "             'X-Amzn-Trace-Id': 'Root=1-643ce98f-1bb5e28703304ead4cd8c069'},\n",
      " 'origin': '222.112.208.66',\n",
      " 'url': 'http://httpbin.org/get?name=홍길동&age=20&address=서울시+강남구'}\n"
     ]
    }
   ],
   "source": [
    "# 유저 에이전트 설정 -> 웹브라우저 정보를 설정\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent' : user_agent,\n",
    "    'my_header' : 'my_value'   \n",
    "}\n",
    "\n",
    "response = requests.get(url,    # 요청 URL\n",
    "                        params=req_param, # 요청 파라미터\n",
    "                        headers=headers)  # 요청 헤더\n",
    "\n",
    "print(f'상태코드 : {response.status_code}')\n",
    "if response.status_code == 200:\n",
    "    # print(response.text)\n",
    "    txt = response.json()\n",
    "    print(type(txt))\n",
    "    pprint(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Post 요청 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상태코드 : 200\n",
      "<class 'dict'>\n",
      "{'args': {},\n",
      " 'data': '',\n",
      " 'files': {},\n",
      " 'form': {'address': '서울시 강남구', 'age': '20', 'name': '홍길동'},\n",
      " 'headers': {'Accept': '*/*',\n",
      "             'Accept-Encoding': 'gzip, deflate, br',\n",
      "             'Content-Length': '103',\n",
      "             'Content-Type': 'application/x-www-form-urlencoded',\n",
      "             'Host': 'httpbin.org',\n",
      "             'My-Data': 'my_value',\n",
      "             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
      "                           'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
      "                           'Chrome/114.0.0.0 Safari/537.36',\n",
      "             'X-Amzn-Trace-Id': 'Root=1-643ce9cb-7639204c3d35c8eb2e4c66ad'},\n",
      " 'json': None,\n",
      " 'origin': '222.112.208.66',\n",
      " 'url': 'http://httpbin.org/post'}\n"
     ]
    }
   ],
   "source": [
    "# 유저 에이전트 설정 -> 웹브라우저 정보를 설정\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent' : user_agent,\n",
    "    'my_data' : 'my_value'   \n",
    "}\n",
    "\n",
    "url = base_url.format('post')\n",
    "url\n",
    "\n",
    "response = requests.post(url,    # 요청 URL\n",
    "                        data=req_param, # 요청 파라미터\n",
    "                        headers=headers)  # 요청 헤더\n",
    "\n",
    "print(f'상태코드 : {response.status_code}')\n",
    "if response.status_code == 200:\n",
    "    txt = response.json()\n",
    "    print(type(txt))\n",
    "    pprint(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상태코드 : 200\n",
      "<class 'dict'>\n",
      "{'args': {},\n",
      " 'data': '',\n",
      " 'files': {'notebook': '{\\n'\n",
      "                       ' \"cells\": [\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"slide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"# requests 모듈을 이용한 웹 요청\\\\n\",\\n'\n",
      "                       '    \"- [Requests '\n",
      "                       '홈페이지](https://requests.kennethreitz.org/en/master/)\\\\n\",\\n'\n",
      "                       '    \"- **HTTP 요청을 처리하는 파이썬 패키지**\\\\n\",\\n'\n",
      "                       '    \"- get/post 방식 모두를 지원하며 쿠키, 헤더정보등을 HTTP의 다양한 요청처리를 '\n",
      "                       '지원한다.\\\\n\",\\n'\n",
      "                       '    \"- 설치\\\\n\",\\n'\n",
      "                       '    \"    - `pip install requests`\\\\n\",\\n'\n",
      "                       '    \"    - `conda install -c conda-forge requests`\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"## Crawling을 위한 requests 코딩 패턴\\\\n\",\\n'\n",
      "                       '    \"1. requests의 get()/post() 함수를 이용해 url을 넣어 서버 '\n",
      "                       '요청한다.\\\\n\",\\n'\n",
      "                       '    \"3. 응답받은 내용을 처리.\\\\n\",\\n'\n",
      "                       '    \"    - text(HTML)은 BeautifulSoup에 넣어 parsing\\\\n\",\\n'\n",
      "                       '    \"    - binary 파일의 경우 파일출력을 이용해 local에 저장\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"slide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"## 요청 함수\\\\n\",\\n'\n",
      "                       '    \"- get(): GET방식 요청\\\\n\",\\n'\n",
      "                       '    \"- post(): POST방식 요청\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"slide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"### requests.get(URL)\\\\n\",\\n'\n",
      "                       '    \"- **GET 방식 요청**\\\\n\",\\n'\n",
      "                       '    \"- **주요 매개변수**\\\\n\",\\n'\n",
      "                       '    \"    - params: 요청파라미터를 dictionary로 전달\\\\n\",\\n'\n",
      "                       '    \"    - headers: HTTP 요청 header를 dictionary로 '\n",
      "                       '전달\\\\n\",\\n'\n",
      "                       '    \"        - \\'User-Agent\\', \\'Referer\\' 등 헤더 '\n",
      "                       '설정\\\\n\",\\n'\n",
      "                       '    \"    - cookies: 쿠키정보를 전달\\\\n\",\\n'\n",
      "                       '    \"- **반환값(Return Value)**\\\\n\",\\n'\n",
      "                       '    \"    - [Response](#Response객체): 응답결과\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"### requests.post(URL)\\\\n\",\\n'\n",
      "                       '    \"- **POST 방식 요청**\\\\n\",\\n'\n",
      "                       '    \"- **주요 매개변수**\\\\n\",\\n'\n",
      "                       '    \"    - datas : 요청파라미터를 dictionary로 전달\\\\n\",\\n'\n",
      "                       '    \"    - files : 업로드할 파일을 dictionary로 전달\\\\n\",\\n'\n",
      "                       '    \"        - key: 이름, value: 파일과 연결된 '\n",
      "                       'InputStream(TextIOWrapper)\\\\n\",\\n'\n",
      "                       '    \"    - headers: HTTP 요청 header를 dictionary로 '\n",
      "                       '전달\\\\n\",\\n'\n",
      "                       '    \"        - \\'User-Agent\\', \\'Referer\\' 등 헤더 '\n",
      "                       '설정\\\\n\",\\n'\n",
      "                       '    \"    - cookies: 쿠키정보를 전달\\\\n\",\\n'\n",
      "                       '    \"- **반환값(Return Value)**\\\\n\",\\n'\n",
      "                       '    \"    - [Response](#Response객체): 응답결과\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"subslide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"> ### 요청파라미터(Request Parameter)\\\\n\",\\n'\n",
      "                       '    \"> - 요청파라미터란?\\\\n\",\\n'\n",
      "                       '    \">     - 서버가 일하기 위해 클라이언트로 부터 받아야하는 값들\\\\n\",\\n'\n",
      "                       '    \">     - `name=value` 형태이며 여러개일 경우 `&`로 연결해서 '\n",
      "                       '전송됨\\\\n\",\\n'\n",
      "                       '    \"> - Get 요청시 queryString 으로 전달\\\\n\",\\n'\n",
      "                       '    \">     - querystring : URL 뒤에 붙여서 전송한다.\\\\n\",\\n'\n",
      "                       '    \">     - ex) '\n",
      "                       'https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=python\\\\n\",\\n'\n",
      "                       '    \">     - requests.get() 요청시 \\\\n\",\\n'\n",
      "                       '    \">         1. url 뒤에 querystring으로 붙여서 전송\\\\n\",\\n'\n",
      "                       '    \">         2. dictionary 에 name=value 형태로 만들어 매개변수 '\n",
      "                       'params에 전달\\\\n\",\\n'\n",
      "                       '    \"> - Post 요청시 요청정보의 body에 넣어 전달\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"> ### HTTP 요청 헤더(Request Header)\\\\n\",\\n'\n",
      "                       '    \"> HTTP 요청시 웹브라우저가 client의 여러 부가적인 정보들을 Key-Value '\n",
      "                       '쌍 형식으로 전달한다.\\\\n\",\\n'\n",
      "                       '    \"> - accept: 클라이언트가 처리가능한 content 타입 (Mime-type '\n",
      "                       '형식으로 전달)\\\\n\",\\n'\n",
      "                       '    \"> - accept-language: 클라이언트가 지원하는 언어(ex: ko, '\n",
      "                       'en-US)\\\\n\",\\n'\n",
      "                       '    \"> - host: 요청한 host \\\\n\",\\n'\n",
      "                       '    \"> - user-agent: 웹브라우저 종류\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"slide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"## Response객체 -  응답데이터\\\\n\",\\n'\n",
      "                       '    \"- get()/post() 의 요청에 대한 서버의 응답 결과를 Response에 담아 '\n",
      "                       '반환\\\\n\",\\n'\n",
      "                       '    \"    - Response의 속성을 이용해 응답결과를 조회\\\\n\",\\n'\n",
      "                       '    \"- 주요 속성(Attribut)\\\\n\",\\n'\n",
      "                       '    \"    - **url**\\\\n\",\\n'\n",
      "                       '    \"        - 응답 받은(요청한) url \\\\n\",\\n'\n",
      "                       '    \"    - **status_code**\\\\n\",\\n'\n",
      "                       '    \"        - HTTP 응답 상태코드\\\\n\",\\n'\n",
      "                       '    \"    - **headers**\\\\n\",\\n'\n",
      "                       '    \"        - 응답 header 정보를 dictionary로 반환\\\\n\",\\n'\n",
      "                       '    \"- **응답 결과 조회**\\\\n\",\\n'\n",
      "                       '    \"    - **text**\\\\n\",\\n'\n",
      "                       '    \"        - 응답내용(html을 str로 반환)\\\\n\",\\n'\n",
      "                       '    \"    - **content**\\\\n\",\\n'\n",
      "                       '    \"        - 응답내용(응답결과가 binary-image, 동영상등- 일 경우사용하며 '\n",
      "                       'bytes로 반환)\\\\n\",\\n'\n",
      "                       '    \"    - **json()**\\\\n\",\\n'\n",
      "                       '    \"        - 응답 결과가 JSON 인 경우 dictionary로 변환해서 반환\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": 10,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [\\n'\n",
      "                       '    {\\n'\n",
      "                       '     \"name\": \"stdout\",\\n'\n",
      "                       '     \"output_type\": \"stream\",\\n'\n",
      "                       '     \"text\": [\\n'\n",
      "                       '      \"<class \\'str\\'>\\\\n\"\\n'\n",
      "                       '     ]\\n'\n",
      "                       '    }\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"import re\\\\n\",\\n'\n",
      "                       '    \"import requests\\\\n\",\\n'\n",
      "                       '    \"from bs4 import BeautifulSoup as bs\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"url = r\\'https://www.naver.com/\\'\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"res = requests.get(url)\\\\n\",\\n'\n",
      "                       '    \"print(type(res.text))\\\\n\",\\n'\n",
      "                       '    \"soup = bs(res.text, \\'html.parser\\')\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"> ### JSON(JavaScript Object Notation)\\\\n\",\\n'\n",
      "                       '    \"> key-value 형태 또는 배열 형태의 text이며 이 기종간 데이터 교환에 많이 '\n",
      "                       '사용된다. 자바스크립트 언어에서 Object와 array를 생성하는 문법을 이용해 만듬. '\n",
      "                       '\\\\n\",\\n'\n",
      "                       '    \"- [JSON 공식사이트](http://json.org)\\\\n\",\\n'\n",
      "                       '    \">\\\\n\",\\n'\n",
      "                       '    \"> ### json 모듈\\\\n\",\\n'\n",
      "                       '    \"> JSON 형식 문자열을 다루는 모듈\\\\n\",\\n'\n",
      "                       '    \"> - json.loads(json문자열)\\\\n\",\\n'\n",
      "                       '    \">    - JSON 형식 문자열을 dictionary로 변환\\\\n\",\\n'\n",
      "                       '    \"> - json.dumps(dictionary)\\\\n\",\\n'\n",
      "                       '    \">    - dictionary를 JSON 형식 문자열로 변환\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"> ### HTTP 응답 상태코드\\\\n\",\\n'\n",
      "                       '    \"> - '\n",
      "                       'https://developer.mozilla.org/ko/docs/Web/HTTP/Status '\n",
      "                       '\\\\n\",\\n'\n",
      "                       '    \"- 2XX: 성공\\\\n\",\\n'\n",
      "                       '    \"    - 200: OK\\\\n\",\\n'\n",
      "                       '    \"- 3XX: 다른 주소로 이동 (이사)\\\\n\",\\n'\n",
      "                       '    \"    - 300번대이면 자동으로 이동해 준다. 크롤링시는 볼일이 별로 없다.\\\\n\",\\n'\n",
      "                       '    \"- 4XX: 클라이언트 오류 (사용자가 잘못한 것)\\\\n\",\\n'\n",
      "                       '    \"  - 404: 존재하지 않는 주소\\\\n\",\\n'\n",
      "                       '    \"- 5XX: 서버 오류 (서버에서 문제생긴 것)\\\\n\",\\n'\n",
      "                       '    \"  - 500: 서버가 처리방법을 모르는 오류\\\\n\",\\n'\n",
      "                       '    \"  - 503: 서버가 다운 등의 문제로 서비스 불가 상태\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"### Get 방식 요청 예제\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": 22,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [\\n'\n",
      "                       '    {\\n'\n",
      "                       '     \"name\": \"stdout\",\\n'\n",
      "                       '     \"output_type\": \"stream\",\\n'\n",
      "                       '     \"text\": [\\n'\n",
      "                       '      \"200\\\\n\",\\n'\n",
      "                       '      \"<class \\'dict\\'>\\\\n\",\\n'\n",
      "                       '      \"{\\'args\\': {},\\\\n\",\\n'\n",
      "                       '      \" \\'headers\\': {\\'Accept\\': \\'*/*\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Accept-Encoding\\': \\'gzip, '\n",
      "                       'deflate, br\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Host\\': \\'httpbin.org\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'User-Agent\\': '\n",
      "                       '\\'python-requests/2.28.1\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'X-Amzn-Trace-Id\\': '\n",
      "                       '\\'Root=1-643ce7d8-439ea8851527a06679999173\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'origin\\': \\'222.112.208.66\\',\\\\n\",\\n'\n",
      "                       '      \" \\'url\\': \\'http://httpbin.org/get\\'}\\\\n\"\\n'\n",
      "                       '     ]\\n'\n",
      "                       '    }\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"import requests\\\\n\",\\n'\n",
      "                       '    \"from bs4 import BeautifulSoup as bs\\\\n\",\\n'\n",
      "                       '    \"from pprint import pprint\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"base_url = r\\'http://httpbin.org/{}\\'\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"url = base_url.format(\\'get\\')\\\\n\",\\n'\n",
      "                       '    \"url\\\\n\",\\n'\n",
      "                       '    \"response = requests.get(url)\\\\n\",\\n'\n",
      "                       '    \"print(response.status_code)\\\\n\",\\n'\n",
      "                       '    \"if response.status_code == 200:\\\\n\",\\n'\n",
      "                       '    \"    # print(response.text)\\\\n\",\\n'\n",
      "                       '    \"    txt = response.json()\\\\n\",\\n'\n",
      "                       '    \"    print(type(txt))\\\\n\",\\n'\n",
      "                       '    \"    pprint(txt)\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": 30,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [\\n'\n",
      "                       '    {\\n'\n",
      "                       '     \"name\": \"stdout\",\\n'\n",
      "                       '     \"output_type\": \"stream\",\\n'\n",
      "                       '     \"text\": [\\n'\n",
      "                       '      \"상태코드 : 200\\\\n\",\\n'\n",
      "                       '      \"<class \\'dict\\'>\\\\n\",\\n'\n",
      "                       '      \"{\\'args\\': {\\'address\\': \\'서울시 강남구\\', \\'age\\': '\n",
      "                       '\\'20\\', \\'name\\': \\'홍길동\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'headers\\': {\\'Accept\\': \\'*/*\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Accept-Encoding\\': \\'gzip, '\n",
      "                       'deflate, br\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Host\\': \\'httpbin.org\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'User-Agent\\': '\n",
      "                       '\\'python-requests/2.28.1\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'X-Amzn-Trace-Id\\': '\n",
      "                       '\\'Root=1-643ce98d-3817e6b42bb57ce2741a1f3b\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'origin\\': \\'222.112.208.66\\',\\\\n\",\\n'\n",
      "                       '      \" \\'url\\': '\n",
      "                       '\\'http://httpbin.org/get?name=홍길동&age=20&address=서울시+강남구\\'}\\\\n\"\\n'\n",
      "                       '     ]\\n'\n",
      "                       '    }\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"# 파라미터 전달\\\\n\",\\n'\n",
      "                       '    \"# 전달할 파라미터를 딕셔너리 형태로 만들어서 params 인자에 전달\\\\n\",\\n'\n",
      "                       '    \"req_param = {\\\\n\",\\n'\n",
      "                       '    \"    \\'name\\' : \\'홍길동\\',\\\\n\",\\n'\n",
      "                       '    \"    \\'age\\' : 20,\\\\n\",\\n'\n",
      "                       '    \"    \\'address\\' : \\'서울시 강남구\\'\\\\n\",\\n'\n",
      "                       '    \"}\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"response = requests.get(url, '\n",
      "                       'params=req_param)\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"print(f\\'상태코드 : {response.status_code}\\')\\\\n\",\\n'\n",
      "                       '    \"if response.status_code == 200:\\\\n\",\\n'\n",
      "                       '    \"    # print(response.text)\\\\n\",\\n'\n",
      "                       '    \"    txt = response.json()\\\\n\",\\n'\n",
      "                       '    \"    print(type(txt))\\\\n\",\\n'\n",
      "                       '    \"    pprint(txt)\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": 31,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [\\n'\n",
      "                       '    {\\n'\n",
      "                       '     \"name\": \"stdout\",\\n'\n",
      "                       '     \"output_type\": \"stream\",\\n'\n",
      "                       '     \"text\": [\\n'\n",
      "                       '      \"상태코드 : 200\\\\n\",\\n'\n",
      "                       '      \"<class \\'dict\\'>\\\\n\",\\n'\n",
      "                       '      \"{\\'args\\': {\\'address\\': \\'서울시 강남구\\', \\'age\\': '\n",
      "                       '\\'20\\', \\'name\\': \\'홍길동\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'headers\\': {\\'Accept\\': \\'*/*\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Accept-Encoding\\': \\'gzip, '\n",
      "                       'deflate, br\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Host\\': \\'httpbin.org\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'My-Header\\': \\'my_value\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'User-Agent\\': \\'Mozilla/5.0 '\n",
      "                       '(Windows NT 10.0; Win64; x64) \\'\\\\n\",\\n'\n",
      "                       '      \"                           \\'AppleWebKit/537.36 '\n",
      "                       '(KHTML, like Gecko) \\'\\\\n\",\\n'\n",
      "                       '      \"                           \\'Chrome/114.0.0.0 '\n",
      "                       'Safari/537.36\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'X-Amzn-Trace-Id\\': '\n",
      "                       '\\'Root=1-643ce98f-1bb5e28703304ead4cd8c069\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'origin\\': \\'222.112.208.66\\',\\\\n\",\\n'\n",
      "                       '      \" \\'url\\': '\n",
      "                       '\\'http://httpbin.org/get?name=홍길동&age=20&address=서울시+강남구\\'}\\\\n\"\\n'\n",
      "                       '     ]\\n'\n",
      "                       '    }\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"# 유저 에이전트 설정 -> 웹브라우저 정보를 설정\\\\n\",\\n'\n",
      "                       '    \"user_agent = \\'Mozilla/5.0 (Windows NT 10.0; '\n",
      "                       'Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
      "                       'Chrome/114.0.0.0 Safari/537.36\\'\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"headers = {\\\\n\",\\n'\n",
      "                       '    \"    \\'User-Agent\\' : user_agent,\\\\n\",\\n'\n",
      "                       '    \"    \\'my_header\\' : \\'my_value\\'   \\\\n\",\\n'\n",
      "                       '    \"}\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"response = requests.get(url,    # 요청 URL\\\\n\",\\n'\n",
      "                       '    \"                        params=req_param, # 요청 '\n",
      "                       '파라미터\\\\n\",\\n'\n",
      "                       '    \"                        headers=headers)  # 요청 '\n",
      "                       '헤더\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"print(f\\'상태코드 : {response.status_code}\\')\\\\n\",\\n'\n",
      "                       '    \"if response.status_code == 200:\\\\n\",\\n'\n",
      "                       '    \"    # print(response.text)\\\\n\",\\n'\n",
      "                       '    \"    txt = response.json()\\\\n\",\\n'\n",
      "                       '    \"    print(type(txt))\\\\n\",\\n'\n",
      "                       '    \"    pprint(txt)\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"heading_collapsed\": true\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"### Post 요청 예\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": 37,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [\\n'\n",
      "                       '    {\\n'\n",
      "                       '     \"name\": \"stdout\",\\n'\n",
      "                       '     \"output_type\": \"stream\",\\n'\n",
      "                       '     \"text\": [\\n'\n",
      "                       '      \"상태코드 : 200\\\\n\",\\n'\n",
      "                       '      \"<class \\'dict\\'>\\\\n\",\\n'\n",
      "                       '      \"{\\'args\\': {},\\\\n\",\\n'\n",
      "                       '      \" \\'data\\': \\'\\',\\\\n\",\\n'\n",
      "                       '      \" \\'files\\': {},\\\\n\",\\n'\n",
      "                       '      \" \\'form\\': {\\'address\\': \\'서울시 강남구\\', \\'age\\': '\n",
      "                       '\\'20\\', \\'name\\': \\'홍길동\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'headers\\': {\\'Accept\\': \\'*/*\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Accept-Encoding\\': \\'gzip, '\n",
      "                       'deflate, br\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Content-Length\\': \\'103\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Content-Type\\': '\n",
      "                       '\\'application/x-www-form-urlencoded\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'Host\\': \\'httpbin.org\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'My-Data\\': \\'my_value\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'User-Agent\\': \\'Mozilla/5.0 '\n",
      "                       '(Windows NT 10.0; Win64; x64) \\'\\\\n\",\\n'\n",
      "                       '      \"                           \\'AppleWebKit/537.36 '\n",
      "                       '(KHTML, like Gecko) \\'\\\\n\",\\n'\n",
      "                       '      \"                           \\'Chrome/114.0.0.0 '\n",
      "                       'Safari/537.36\\',\\\\n\",\\n'\n",
      "                       '      \"             \\'X-Amzn-Trace-Id\\': '\n",
      "                       '\\'Root=1-643ce9cb-7639204c3d35c8eb2e4c66ad\\'},\\\\n\",\\n'\n",
      "                       '      \" \\'json\\': None,\\\\n\",\\n'\n",
      "                       '      \" \\'origin\\': \\'222.112.208.66\\',\\\\n\",\\n'\n",
      "                       '      \" \\'url\\': \\'http://httpbin.org/post\\'}\\\\n\"\\n'\n",
      "                       '     ]\\n'\n",
      "                       '    }\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"# 유저 에이전트 설정 -> 웹브라우저 정보를 설정\\\\n\",\\n'\n",
      "                       '    \"user_agent = \\'Mozilla/5.0 (Windows NT 10.0; '\n",
      "                       'Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
      "                       'Chrome/114.0.0.0 Safari/537.36\\'\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"headers = {\\\\n\",\\n'\n",
      "                       '    \"    \\'User-Agent\\' : user_agent,\\\\n\",\\n'\n",
      "                       '    \"    \\'my_data\\' : \\'my_value\\'   \\\\n\",\\n'\n",
      "                       '    \"}\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"url = base_url.format(\\'post\\')\\\\n\",\\n'\n",
      "                       '    \"url\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"response = requests.post(url,    # 요청 URL\\\\n\",\\n'\n",
      "                       '    \"                        data=req_param, # 요청 '\n",
      "                       '파라미터\\\\n\",\\n'\n",
      "                       '    \"                        headers=headers)  # 요청 '\n",
      "                       '헤더\\\\n\",\\n'\n",
      "                       '    \"\\\\n\",\\n'\n",
      "                       '    \"print(f\\'상태코드 : {response.status_code}\\')\\\\n\",\\n'\n",
      "                       '    \"if response.status_code == 200:\\\\n\",\\n'\n",
      "                       '    \"    txt = response.json()\\\\n\",\\n'\n",
      "                       '    \"    print(type(txt))\\\\n\",\\n'\n",
      "                       '    \"    pprint(txt)\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"markdown\",\\n'\n",
      "                       '   \"metadata\": {\\n'\n",
      "                       '    \"slideshow\": {\\n'\n",
      "                       '     \"slide_type\": \"slide\"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"### 응답결과(Response) 조회\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  },\\n'\n",
      "                       '  {\\n'\n",
      "                       '   \"cell_type\": \"code\",\\n'\n",
      "                       '   \"execution_count\": null,\\n'\n",
      "                       '   \"metadata\": {},\\n'\n",
      "                       '   \"outputs\": [],\\n'\n",
      "                       '   \"source\": [\\n'\n",
      "                       '    \"url = '\n",
      "                       '\\'http://www.pythonscraping.com/pages/warandpeace.html\\'\"\\n'\n",
      "                       '   ]\\n'\n",
      "                       '  }\\n'\n",
      "                       ' ],\\n'\n",
      "                       ' \"metadata\": {\\n'\n",
      "                       '  \"kernelspec\": {\\n'\n",
      "                       '   \"display_name\": \"Python 3 (ipykernel)\",\\n'\n",
      "                       '   \"language\": \"python\",\\n'\n",
      "                       '   \"name\": \"python3\"\\n'\n",
      "                       '  },\\n'\n",
      "                       '  \"language_info\": {\\n'\n",
      "                       '   \"codemirror_mode\": {\\n'\n",
      "                       '    \"name\": \"ipython\",\\n'\n",
      "                       '    \"version\": 3\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"file_extension\": \".py\",\\n'\n",
      "                       '   \"mimetype\": \"text/x-python\",\\n'\n",
      "                       '   \"name\": \"python\",\\n'\n",
      "                       '   \"nbconvert_exporter\": \"python\",\\n'\n",
      "                       '   \"pygments_lexer\": \"ipython3\",\\n'\n",
      "                       '   \"version\": \"3.10.9\"\\n'\n",
      "                       '  },\\n'\n",
      "                       '  \"toc\": {\\n'\n",
      "                       '   \"base_numbering\": 1,\\n'\n",
      "                       '   \"nav_menu\": {},\\n'\n",
      "                       '   \"number_sections\": true,\\n'\n",
      "                       '   \"sideBar\": false,\\n'\n",
      "                       '   \"skip_h1_title\": false,\\n'\n",
      "                       '   \"title_cell\": \"Table of Contents\",\\n'\n",
      "                       '   \"title_sidebar\": \"Contents\",\\n'\n",
      "                       '   \"toc_cell\": false,\\n'\n",
      "                       '   \"toc_position\": {},\\n'\n",
      "                       '   \"toc_section_display\": false,\\n'\n",
      "                       '   \"toc_window_display\": false\\n'\n",
      "                       '  },\\n'\n",
      "                       '  \"varInspector\": {\\n'\n",
      "                       '   \"cols\": {\\n'\n",
      "                       '    \"lenName\": 16,\\n'\n",
      "                       '    \"lenType\": 16,\\n'\n",
      "                       '    \"lenVar\": 40\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"kernels_config\": {\\n'\n",
      "                       '    \"python\": {\\n'\n",
      "                       '     \"delete_cmd_postfix\": \"\",\\n'\n",
      "                       '     \"delete_cmd_prefix\": \"del \",\\n'\n",
      "                       '     \"library\": \"var_list.py\",\\n'\n",
      "                       '     \"varRefreshCmd\": \"print(var_dic_list())\"\\n'\n",
      "                       '    },\\n'\n",
      "                       '    \"r\": {\\n'\n",
      "                       '     \"delete_cmd_postfix\": \") \",\\n'\n",
      "                       '     \"delete_cmd_prefix\": \"rm(\",\\n'\n",
      "                       '     \"library\": \"var_list.r\",\\n'\n",
      "                       '     \"varRefreshCmd\": \"cat(var_dic_list()) \"\\n'\n",
      "                       '    }\\n'\n",
      "                       '   },\\n'\n",
      "                       '   \"types_to_exclude\": [\\n'\n",
      "                       '    \"module\",\\n'\n",
      "                       '    \"function\",\\n'\n",
      "                       '    \"builtin_function_or_method\",\\n'\n",
      "                       '    \"instance\",\\n'\n",
      "                       '    \"_Feature\"\\n'\n",
      "                       '   ],\\n'\n",
      "                       '   \"window_display\": false\\n'\n",
      "                       '  }\\n'\n",
      "                       ' },\\n'\n",
      "                       ' \"nbformat\": 4,\\n'\n",
      "                       ' \"nbformat_minor\": 2\\n'\n",
      "                       '}\\n'},\n",
      " 'form': {'address': '서울시 강남구', 'age': '20', 'name': '홍길동'},\n",
      " 'headers': {'Accept': '*/*',\n",
      "             'Accept-Encoding': 'gzip, deflate, br',\n",
      "             'Content-Length': '15328',\n",
      "             'Content-Type': 'multipart/form-data; '\n",
      "                             'boundary=389b61c7f90b02c42d9ab0b858ae6c80',\n",
      "             'Host': 'httpbin.org',\n",
      "             'My-Data': 'my_value',\n",
      "             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
      "                           'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
      "                           'Chrome/114.0.0.0 Safari/537.36',\n",
      "             'X-Amzn-Trace-Id': 'Root=1-643cebd1-425685e84fc04d3a5be54e4a'},\n",
      " 'json': None,\n",
      " 'origin': '222.112.208.66',\n",
      " 'url': 'http://httpbin.org/post'}\n"
     ]
    }
   ],
   "source": [
    "# 유저 에이전트 설정 -> 웹브라우저 정보를 설정\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent' : user_agent,\n",
    "    'my_data' : 'my_value'   \n",
    "}\n",
    "f= open('02_requests.ipynb', 'rb')\n",
    "files = {\n",
    "    'notebook' : f\n",
    "}\n",
    "\n",
    "url = base_url.format('post')\n",
    "url\n",
    "\n",
    "response = requests.post(url,    # 요청 URL\n",
    "                        data=req_param, # 요청 파라미터\n",
    "                        headers=headers, # 요청 헤더\n",
    "                        files=files)  # 요청 파일\n",
    "f.close()\n",
    "\n",
    "print(f'상태코드 : {response.status_code}')\n",
    "if response.status_code == 200:\n",
    "    txt = response.json()\n",
    "    print(type(txt))\n",
    "    pprint(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 응답결과(Response) 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초록색 글자\n",
    "# #text > p:nth-child(7) > span.green\n",
    "# #text > p:nth-child(2) > span:nth-child(3)\n",
    "# #text > p:nth-child(2) > span:nth-child(5)\n",
    "\n",
    "# 정리해보면\n",
    "# #text > p > span.green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "['Anna Pavlovna Scherer',\n",
      " 'Empress Marya Fedorovna',\n",
      " 'Prince Vasili Kuragin',\n",
      " 'Anna Pavlovna',\n",
      " 'St. Petersburg',\n",
      " 'the prince',\n",
      " 'Anna Pavlovna',\n",
      " 'Anna Pavlovna',\n",
      " 'the prince',\n",
      " 'the prince',\n",
      " 'the prince',\n",
      " 'Prince Vasili',\n",
      " 'Anna Pavlovna',\n",
      " 'Anna Pavlovna',\n",
      " 'the prince',\n",
      " 'Wintzingerode',\n",
      " 'King of Prussia',\n",
      " 'le Vicomte de Mortemart',\n",
      " 'Montmorencys',\n",
      " 'Rohans',\n",
      " 'Abbe Morio',\n",
      " 'the Emperor',\n",
      " 'the prince',\n",
      " 'Prince Vasili',\n",
      " 'Dowager Empress Marya Fedorovna',\n",
      " 'the baron',\n",
      " 'Anna Pavlovna',\n",
      " 'the Empress',\n",
      " 'the Empress',\n",
      " \"Anna Pavlovna's\",\n",
      " 'Her Majesty',\n",
      " 'Baron Funke',\n",
      " 'The prince',\n",
      " 'Anna Pavlovna',\n",
      " 'the Empress',\n",
      " 'The prince',\n",
      " 'Anatole',\n",
      " 'the prince',\n",
      " 'The prince',\n",
      " 'Anna Pavlovna',\n",
      " 'Anna Pavlovna']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent' : user_agent\n",
    "}\n",
    "# 유저에이전트가 웹 크롤러일 경우 서버에서 차단할 수 있음\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "result_green = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = bs(response.text, 'lxml')\n",
    "\n",
    "    tag_list = soup.select('span.green')\n",
    "\n",
    "    pprint(len(tag_list))\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        result_green.append(tag.text.replace('\\n', ' '))\n",
    "else:\n",
    "    pprint(response.status_code)\n",
    "\n",
    "pprint(result_green)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .\\testfiles\\todaynews.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .\\testfiles\\todaynews.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "def get_news_list():\n",
    "    daum_news_url = r'https://news.daum.net/'\n",
    "\n",
    "    # 유저에이전트가 웹 크롤러일 경우 서버에서 차단할 수 있음\n",
    "    response = requests.get(daum_news_url, headers=headers)\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(7) > div > div > strong > a\n",
    "\n",
    "    news_list = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        for i in range(1, 20):\n",
    "            try: \n",
    "                tag = soup.select_one(f'div.box_g.box_news_issue > ul > li:nth-child({i}) > div > div > strong > a')\n",
    "                t = [tag.text.replace('\\n', ' ').strip(), tag['href']]\n",
    "                news_list.append(t)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "    else:\n",
    "        pprint(response.status_code)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "            'title' : [news[0] for news in news_list],\n",
    "            'url' : [news[1] for news in news_list]\n",
    "        })\n",
    "        \n",
    "        \n",
    "    return  df\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "file_path = r'news_{}.csv'.format(d)\n",
    "result = get_news_list()\n",
    "result.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "file_path = r'.\\testfiles\\news_{}.csv'.format(d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv파일로 나오는 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .\\testfiles\\todaynews_and_contents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .\\testfiles\\todaynews_and_contents.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "def get_news_content(news_list):\n",
    "    \"\"\"뉴스의 내용을 가져오는 함수\n",
    "\n",
    "    Args:\n",
    "        news_list (list): 정보를 받아올 뉴스의 제목과 url이 담긴 딕셔너리를 담은 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    for i, news in enumerate(news_list):\n",
    "        url = news['url']\n",
    "        # 뉴스의 url로 get() 요청을 보내서 응답을 받아옴\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(4)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        \n",
    "        # 요청이 성공했을 경우\n",
    "        if response.status_code == 200:\n",
    "            # 요청을 beutifulsoup에 넣어서 파싱\n",
    "            soup = bs(response.text, 'lxml')\n",
    "            # 뉴스 내용을 가져오는 css selector\n",
    "            tags = soup.select('#mArticle > div.news_view section > p')\n",
    "            # 가져온 내용들을 하나의 문자열로 만들어서 news['content']에 저장\n",
    "            for tag in tags:\n",
    "                news['content'] += tag.text.replace('\\n', ' ').strip()\n",
    "        # 요청이 실패했을 경우, 상태코드를 출력\n",
    "        else:\n",
    "            pprint(response.status_code)\n",
    "        \n",
    "        news_list[i] = news\n",
    "    \n",
    "    return news_list\n",
    "\n",
    "def get_news_list():\n",
    "    \"\"\"다음 뉴스의 제목과 url, 내용을 가져오는 함수\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    daum_news_url = r'https://news.daum.net/'\n",
    "\n",
    "    # 유저에이전트가 웹 크롤러일 경우 서버에서 차단할 수 있음\n",
    "    # 다음 뉴스의 메인 페이지로 get() 요청을 보내서 응답을 받아옴\n",
    "    response = requests.get(daum_news_url, headers=headers)\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(7) > div > div > strong > a\n",
    "\n",
    "    # 뉴스의 제목과 url을 저장할 리스트\n",
    "    news_list = []\n",
    "    # 요청이 성공했을 경우\n",
    "    if response.status_code == 200:\n",
    "        # 요청을 beutifulsoup에 넣어서 파싱\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        \n",
    "        # 메인 뉴스를 모두 가져오기 위한 반복문\n",
    "        i = 0\n",
    "        while True:\n",
    "            try: \n",
    "                i += 1\n",
    "                # 메인 뉴스의 제목과 url을 가져오는 css selector\n",
    "                tag = soup.select_one(f'div.box_g.box_news_issue > ul > li:nth-child({i}) > div > div > strong > a')\n",
    "                # 가져온 제목과 url을 딕셔너리로 만들어서 news_list에 저장,\n",
    "                # 뉴스 내용은 아직 가져오지 않음\n",
    "                t = { 'title' : tag.text.replace('\\n', ' ').strip(), 'url' : tag['href'], 'content' : ''}\n",
    "                news_list.append(t)\n",
    "            except:\n",
    "                break\n",
    "    # 요청이 실패했을 경우, 상태코드를 출력\n",
    "    else:\n",
    "        pprint(response.status_code)\n",
    "    \n",
    "    # 뉴스의 컨텐츠를 가져오는 함수 호출\n",
    "    news_list = get_news_content(news_list)\n",
    "    \n",
    "    # 가져온 뉴스의 제목, url, 컨텐츠를 데이터프레임으로 만들어서 반환\n",
    "    df = pd.DataFrame({\n",
    "            'title' : [news['title'] for news in news_list],\n",
    "            'url' : [news['url'] for news in news_list],\n",
    "            'content' : [news['content'] for news in news_list]\n",
    "        })\n",
    "        \n",
    "    return  df\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "file_path = r'news_and_contents_{}.csv'.format(d)\n",
    "result = get_news_list()\n",
    "result.to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 판다스 데이터로 나오는 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[직설] MZ가 주 69시간제 멈췄다?…근로시간 유연화 vs. 주 4.5일제</td>\n",
       "      <td>https://v.daum.net/v/20230418105227385</td>\n",
       "      <td>■ 용감한 토크쇼 직설 - 조동근 명지대 경제학과 명예교수, 김성희 고려대 노동문제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日언론 \"美 전기차 보조금에 日·유럽·韓 업체 제외…반발 거셀 것\"</td>\n",
       "      <td>https://v.daum.net/v/20230418105842731</td>\n",
       "      <td>(서울=뉴스1) 김민수 기자 = 미국이 인플레이션 감축법(IRA)에 따라 최대 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>통일부 \"개성공단에 과거보다 많은 北 근로자 출근…재산권 침해\"</td>\n",
       "      <td>https://v.daum.net/v/20230418110121998</td>\n",
       "      <td>(서울=뉴스1) 이설 기자 = 통일부는 18일 북한이 개성공단 내 한국 측 자산을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>박홍근 \"송영길, 조기귀국 당 공식 요청에 화답할 것 믿어\"</td>\n",
       "      <td>https://v.daum.net/v/20230418110149044</td>\n",
       "      <td>(서울=뉴스1) 박기호 박종홍 기자 = 박홍근 더불어민주당 원내대표 18일 \"정치인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>日 기시다 테러범, 선거제도에 불만…범행은 정치적 동기?</td>\n",
       "      <td>https://v.daum.net/v/20230418105119344</td>\n",
       "      <td>(서울=뉴스1) 권진영 기자 = 일본 와카야마현(県) 선거 유세 현장에서 기시다 후...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>전기업계 \"생태계 붕괴 위기…미래세대에 떠넘기지 말고 요금 인상해야\"</td>\n",
       "      <td>https://v.daum.net/v/20230418110106958</td>\n",
       "      <td>(세종=뉴스1) 심언기 기자 = 전기관련단체협의회는 18일 \"전기산업계는 생태계 붕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>이낙연, 열흘 일정 마치고 美로 출국…당 상황에 대해선 '침묵'</td>\n",
       "      <td>https://v.daum.net/v/20230418104743102</td>\n",
       "      <td>(인천공항=뉴스1) 이서영 기자 = 이낙연 전 더불어민주당 대표가 열흘간의 일정을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>김포골드라인 긴급대책…24일부터 전세버스 투입·7월 DRT 운영</td>\n",
       "      <td>https://v.daum.net/v/20230418110100943</td>\n",
       "      <td>(수원=연합뉴스) 우영식 기자 = 경기도와 김포시가 '지옥철'이라 불릴 정도로 승객...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[지구촌 돋보기] 잇단 무력시위…중국-타이완 군사 긴장 고조</td>\n",
       "      <td>https://v.daum.net/v/20230418105632589</td>\n",
       "      <td>[앵커]중국이 타이완 주변에 수시로 군용기와 군함을 보내는 등 타이완에 대한 군사적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"한전·가스공사, 매일 50억원 이자…요금 인상 골든타임\"</td>\n",
       "      <td>https://v.daum.net/v/20230418110005798</td>\n",
       "      <td>(서울=연합뉴스) 이슬기 기자 = 한국전력과 한국가스공사의 적자와 미수금이 지난해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"무려 52주 신고가\".. 제2의 에코프로는 바로 이 그룹주?</td>\n",
       "      <td>https://v.daum.net/v/20230418104357911</td>\n",
       "      <td>이에 다음 주자 찾기에 혈안이 된 개인 투자자들은 포스코 그룹에 눈길을 돌리고 있다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>머스크 'AI 개발 중단' 서한에 EU의회 화답…\"필요성 공감…정상회담 열어야\"</td>\n",
       "      <td>https://v.daum.net/v/20230418105236392</td>\n",
       "      <td>(서울=뉴스1) 김성식 기자 = 유럽의회 의원들이 챗GPT와 같은 생성형 인공지능(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>美 시카고서 총격 사건으로 나흘 간 최소 11명 사망</td>\n",
       "      <td>https://v.daum.net/v/20230418110222088</td>\n",
       "      <td>기사내용 요약 술집서 총기 난사…괴한 피하려다 숨지기도[서울=뉴시스] 최현호 기자 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[속보영상] 윤 대통령 “전세사기로 비통한 소식 잇따라…정부 대책 점검해야”</td>\n",
       "      <td>https://v.daum.net/v/20230418110225092</td>\n",
       "      <td>윤석열 대통령은 최근 극단적 선택을 하는 피해자가 잇따라 발생한 인천 전세사기 사건...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"김태효 즉각 해임해야\"‥\"누구에게 도움 되나\"</td>\n",
       "      <td>https://v.daum.net/v/20230418062520611</td>\n",
       "      <td>[뉴스투데이]◀ 앵커 ▶더불어민주당 의원들이 용산 대통령실을 찾아 김태효 국가안보실...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>민선8기 제주도정, 지방비 비중 늘어..\"재정 구성 균형감 떨어져\"</td>\n",
       "      <td>https://v.daum.net/v/20230418110100941</td>\n",
       "      <td>민선8기 제주도정의 공약 소요재정이 민선7기 대비 늘었지만, 지방비 비중이 늘어 재...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>강풍에 '아찔'..'회항' 또 '회항'</td>\n",
       "      <td>https://v.daum.net/v/20230418104947248</td>\n",
       "      <td>태풍급 강풍이 몰아치면서, 제주를 오가는 항공편 결항이 속출하고 있습니다.한국공항공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[단독]'3대 명품시계' 바쉐론 콘스탄틴, 6월부터 가격 11% 인상</td>\n",
       "      <td>https://v.daum.net/v/20230418105957777</td>\n",
       "      <td>[이데일리 백주아 기자] 스위스 명품 시계 브랜드 바쉐론 콘스탄틴이 오는 6월부터 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>수단 유혈충돌, 병원마저 표적…\"인큐베이터 아기 남아있어요\"</td>\n",
       "      <td>https://v.daum.net/v/20230418105759707</td>\n",
       "      <td>(서울=연합뉴스) 최재서 기자 = 아프리카 수단에서 군벌 간 유혈 충돌이 3일째 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[서울의미래]시범아파트부터 타워팰리스까지…한 눈에 보는 아파트 역사</td>\n",
       "      <td>https://v.daum.net/v/20230418090048147</td>\n",
       "      <td>10~15층 높이에 성냥갑 모양대로 일자로 늘어선 아파트, 옆 동과 마주 보는 평행...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0     [직설] MZ가 주 69시간제 멈췄다?…근로시간 유연화 vs. 주 4.5일제   \n",
       "1          日언론 \"美 전기차 보조금에 日·유럽·韓 업체 제외…반발 거셀 것\"   \n",
       "2            통일부 \"개성공단에 과거보다 많은 北 근로자 출근…재산권 침해\"   \n",
       "3              박홍근 \"송영길, 조기귀국 당 공식 요청에 화답할 것 믿어\"   \n",
       "4                日 기시다 테러범, 선거제도에 불만…범행은 정치적 동기?   \n",
       "5         전기업계 \"생태계 붕괴 위기…미래세대에 떠넘기지 말고 요금 인상해야\"   \n",
       "6            이낙연, 열흘 일정 마치고 美로 출국…당 상황에 대해선 '침묵'   \n",
       "7            김포골드라인 긴급대책…24일부터 전세버스 투입·7월 DRT 운영   \n",
       "8              [지구촌 돋보기] 잇단 무력시위…중국-타이완 군사 긴장 고조   \n",
       "9               \"한전·가스공사, 매일 50억원 이자…요금 인상 골든타임\"   \n",
       "10            \"무려 52주 신고가\".. 제2의 에코프로는 바로 이 그룹주?   \n",
       "11  머스크 'AI 개발 중단' 서한에 EU의회 화답…\"필요성 공감…정상회담 열어야\"   \n",
       "12                 美 시카고서 총격 사건으로 나흘 간 최소 11명 사망   \n",
       "13    [속보영상] 윤 대통령 “전세사기로 비통한 소식 잇따라…정부 대책 점검해야”   \n",
       "14                    \"김태효 즉각 해임해야\"‥\"누구에게 도움 되나\"   \n",
       "15         민선8기 제주도정, 지방비 비중 늘어..\"재정 구성 균형감 떨어져\"   \n",
       "16                         강풍에 '아찔'..'회항' 또 '회항'   \n",
       "17        [단독]'3대 명품시계' 바쉐론 콘스탄틴, 6월부터 가격 11% 인상   \n",
       "18             수단 유혈충돌, 병원마저 표적…\"인큐베이터 아기 남아있어요\"   \n",
       "19         [서울의미래]시범아파트부터 타워팰리스까지…한 눈에 보는 아파트 역사   \n",
       "\n",
       "                                       url  \\\n",
       "0   https://v.daum.net/v/20230418105227385   \n",
       "1   https://v.daum.net/v/20230418105842731   \n",
       "2   https://v.daum.net/v/20230418110121998   \n",
       "3   https://v.daum.net/v/20230418110149044   \n",
       "4   https://v.daum.net/v/20230418105119344   \n",
       "5   https://v.daum.net/v/20230418110106958   \n",
       "6   https://v.daum.net/v/20230418104743102   \n",
       "7   https://v.daum.net/v/20230418110100943   \n",
       "8   https://v.daum.net/v/20230418105632589   \n",
       "9   https://v.daum.net/v/20230418110005798   \n",
       "10  https://v.daum.net/v/20230418104357911   \n",
       "11  https://v.daum.net/v/20230418105236392   \n",
       "12  https://v.daum.net/v/20230418110222088   \n",
       "13  https://v.daum.net/v/20230418110225092   \n",
       "14  https://v.daum.net/v/20230418062520611   \n",
       "15  https://v.daum.net/v/20230418110100941   \n",
       "16  https://v.daum.net/v/20230418104947248   \n",
       "17  https://v.daum.net/v/20230418105957777   \n",
       "18  https://v.daum.net/v/20230418105759707   \n",
       "19  https://v.daum.net/v/20230418090048147   \n",
       "\n",
       "                                              content  \n",
       "0   ■ 용감한 토크쇼 직설 - 조동근 명지대 경제학과 명예교수, 김성희 고려대 노동문제...  \n",
       "1   (서울=뉴스1) 김민수 기자 = 미국이 인플레이션 감축법(IRA)에 따라 최대 75...  \n",
       "2   (서울=뉴스1) 이설 기자 = 통일부는 18일 북한이 개성공단 내 한국 측 자산을 ...  \n",
       "3   (서울=뉴스1) 박기호 박종홍 기자 = 박홍근 더불어민주당 원내대표 18일 \"정치인...  \n",
       "4   (서울=뉴스1) 권진영 기자 = 일본 와카야마현(県) 선거 유세 현장에서 기시다 후...  \n",
       "5   (세종=뉴스1) 심언기 기자 = 전기관련단체협의회는 18일 \"전기산업계는 생태계 붕...  \n",
       "6   (인천공항=뉴스1) 이서영 기자 = 이낙연 전 더불어민주당 대표가 열흘간의 일정을 ...  \n",
       "7   (수원=연합뉴스) 우영식 기자 = 경기도와 김포시가 '지옥철'이라 불릴 정도로 승객...  \n",
       "8   [앵커]중국이 타이완 주변에 수시로 군용기와 군함을 보내는 등 타이완에 대한 군사적...  \n",
       "9   (서울=연합뉴스) 이슬기 기자 = 한국전력과 한국가스공사의 적자와 미수금이 지난해 ...  \n",
       "10  이에 다음 주자 찾기에 혈안이 된 개인 투자자들은 포스코 그룹에 눈길을 돌리고 있다...  \n",
       "11  (서울=뉴스1) 김성식 기자 = 유럽의회 의원들이 챗GPT와 같은 생성형 인공지능(...  \n",
       "12  기사내용 요약 술집서 총기 난사…괴한 피하려다 숨지기도[서울=뉴시스] 최현호 기자 ...  \n",
       "13  윤석열 대통령은 최근 극단적 선택을 하는 피해자가 잇따라 발생한 인천 전세사기 사건...  \n",
       "14  [뉴스투데이]◀ 앵커 ▶더불어민주당 의원들이 용산 대통령실을 찾아 김태효 국가안보실...  \n",
       "15  민선8기 제주도정의 공약 소요재정이 민선7기 대비 늘었지만, 지방비 비중이 늘어 재...  \n",
       "16  태풍급 강풍이 몰아치면서, 제주를 오가는 항공편 결항이 속출하고 있습니다.한국공항공...  \n",
       "17  [이데일리 백주아 기자] 스위스 명품 시계 브랜드 바쉐론 콘스탄틴이 오는 6월부터 ...  \n",
       "18  (서울=연합뉴스) 최재서 기자 = 아프리카 수단에서 군벌 간 유혈 충돌이 3일째 이...  \n",
       "19  10~15층 높이에 성냥갑 모양대로 일자로 늘어선 아파트, 옆 동과 마주 보는 평행...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "def get_news_content(news_list):\n",
    "    \"\"\"뉴스의 내용을 가져오는 함수\n",
    "\n",
    "    Args:\n",
    "        news_list (list): 정보를 받아올 뉴스의 제목과 url이 담긴 딕셔너리를 담은 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    for i, news in enumerate(news_list):\n",
    "        url = news['url']\n",
    "        # 뉴스의 url로 get() 요청을 보내서 응답을 받아옴\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(4)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        \n",
    "        # 요청이 성공했을 경우\n",
    "        if response.status_code == 200:\n",
    "            # 요청을 beutifulsoup에 넣어서 파싱\n",
    "            soup = bs(response.text, 'lxml')\n",
    "            # 뉴스 내용을 가져오는 css selector\n",
    "            tags = soup.select('div.news_view section p')\n",
    "            # 가져온 내용들을 하나의 문자열로 만들어서 news['content']에 저장\n",
    "            for tag in tags:\n",
    "                news['content'] += tag.text.replace('\\n', ' ').strip()\n",
    "        # 요청이 실패했을 경우, 상태코드를 출력\n",
    "        else:\n",
    "            pprint(response.status_code)\n",
    "        \n",
    "        news_list[i] = news\n",
    "    \n",
    "    return news_list\n",
    "\n",
    "def get_news_list():\n",
    "    \"\"\"다음 뉴스의 제목과 url, 내용을 가져오는 함수\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    daum_news_url = r'https://news.daum.net/'\n",
    "\n",
    "    # 유저에이전트가 웹 크롤러일 경우 서버에서 차단할 수 있음\n",
    "    # 다음 뉴스의 메인 페이지로 get() 요청을 보내서 응답을 받아옴\n",
    "    response = requests.get(daum_news_url, headers=headers)\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(7) > div > div > strong > a\n",
    "\n",
    "    # 뉴스의 제목과 url을 저장할 리스트\n",
    "    news_list = []\n",
    "    # 요청이 성공했을 경우\n",
    "    if response.status_code == 200:\n",
    "        # 요청을 beutifulsoup에 넣어서 파싱\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        \n",
    "        # 메인 뉴스를 가져오기 위한 반복문\n",
    "        i = 0\n",
    "        while True:\n",
    "            try: \n",
    "                i += 1\n",
    "                # 메인 뉴스의 제목과 url을 가져오는 css selector\n",
    "                tag = soup.select_one(f'div.box_g.box_news_issue > ul > li:nth-child({i}) > div > div > strong > a')\n",
    "                # 가져온 제목과 url을 딕셔너리로 만들어서 news_list에 저장,\n",
    "                # 뉴스 내용은 아직 가져오지 않음\n",
    "                t = { 'title' : tag.text.replace('\\n', ' ').strip(), 'url' : tag['href'], 'content' : ''}\n",
    "                news_list.append(t)\n",
    "            except:\n",
    "                break\n",
    "    # 요청이 실패했을 경우, 상태코드를 출력\n",
    "    else:\n",
    "        pprint(response.status_code)\n",
    "    \n",
    "    # 뉴스의 컨텐츠를 가져오는 함수 호출\n",
    "    news_list = get_news_content(news_list)\n",
    "    \n",
    "    # 가져온 뉴스의 제목, url, 컨텐츠를 데이터프레임으로 만들어서 반환\n",
    "    df = pd.DataFrame({\n",
    "            'title' : [news['title'] for news in news_list],\n",
    "            'url' : [news['url'] for news in news_list],\n",
    "            'content' : [news['content'] for news in news_list]\n",
    "        })\n",
    "        \n",
    "    return  df\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "file_path = r'news_and_contents_{}.csv'.format(d)\n",
    "result = get_news_list()\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 뉴스 기사별 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "def get_news_content(news_list):\n",
    "    \"\"\"뉴스의 내용을 가져오는 함수\n",
    "\n",
    "    Args:\n",
    "        news_list (list): 정보를 받아올 뉴스의 제목과 url이 담긴 딕셔너리를 담은 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    for i, news in enumerate(news_list):\n",
    "        url = news['url']\n",
    "        # 뉴스의 url로 get() 요청을 보내서 응답을 받아옴\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(4)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        # #mArticle > div.news_view.fs_type1 > div.article_view > section > p:nth-child(7)\n",
    "        \n",
    "        # 요청이 성공했을 경우\n",
    "        if response.status_code == 200:\n",
    "            # 요청을 beutifulsoup에 넣어서 파싱\n",
    "            soup = bs(response.text, 'lxml')\n",
    "            # 뉴스 내용을 가져오는 css selector\n",
    "            tags = soup.select('#mArticle > div.news_view section > p')\n",
    "            # 가져온 내용들을 하나의 문자열로 만들어서 news['content']에 저장\n",
    "            for tag in tags:\n",
    "                news['content'] += tag.text.replace('\\n', ' ').strip()\n",
    "        # 요청이 실패했을 경우, 상태코드를 출력\n",
    "        else:\n",
    "            pprint(response.status_code)\n",
    "        \n",
    "        news_list[i] = news\n",
    "    \n",
    "    return news_list\n",
    "\n",
    "def get_news_list():\n",
    "    \"\"\"다음 뉴스의 제목과 url, 내용을 가져오는 함수\n",
    "\n",
    "    Returns:\n",
    "        list: 뉴스의 제목, url, 내용이 담긴 딕셔너리를 담은 리스트\n",
    "    \"\"\"\n",
    "    daum_news_url = r'https://news.daum.net/'\n",
    "\n",
    "    # 유저에이전트가 웹 크롤러일 경우 서버에서 차단할 수 있음\n",
    "    # 다음 뉴스의 메인 페이지로 get() 요청을 보내서 응답을 받아옴\n",
    "    response = requests.get(daum_news_url, headers=headers)\n",
    "\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(1) > div > div > strong > a\n",
    "    # body > div.container-doc > main > section > div > div.content-article\n",
    "    # > div.box_g.box_news_issue > ul > li:nth-child(7) > div > div > strong > a\n",
    "\n",
    "    # 뉴스의 제목과 url을 저장할 리스트\n",
    "    news_list = []\n",
    "    # 요청이 성공했을 경우\n",
    "    if response.status_code == 200:\n",
    "        # 요청을 beutifulsoup에 넣어서 파싱\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        \n",
    "        # 메인 뉴스를 모두 가져오기 위한 반복문\n",
    "        i = 0\n",
    "        while True:\n",
    "            try: \n",
    "                i += 1\n",
    "                # 메인 뉴스의 제목과 url을 가져오는 css selector\n",
    "                tag = soup.select_one(f'div.box_g.box_news_issue > ul > li:nth-child({i}) > div > div > strong > a')\n",
    "                # 가져온 제목과 url을 딕셔너리로 만들어서 news_list에 저장,\n",
    "                # 뉴스 내용은 아직 가져오지 않음\n",
    "                t = { 'title' : tag.text.replace('\\n', ' ').strip(), 'url' : tag['href'], 'content' : ''}\n",
    "                news_list.append(t)\n",
    "            except:\n",
    "                break\n",
    "    # 요청이 실패했을 경우, 상태코드를 출력\n",
    "    else:\n",
    "        pprint(response.status_code)\n",
    "    \n",
    "    # 뉴스의 컨텐츠를 가져오는 함수 호출\n",
    "    news_list = get_news_content(news_list)\n",
    "    \n",
    "    # 가져온 뉴스의 제목, url, 컨텐츠를 데이터프레임으로 만들어서 반환\n",
    "    df = pd.DataFrame({\n",
    "            'title' : [news['title'] for news in news_list],\n",
    "            'url' : [news['url'] for news in news_list],\n",
    "            'content' : [news['content'] for news in news_list]\n",
    "        })\n",
    "        \n",
    "    return  df\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "file_path = r'.\\testfiles\\news_and_contents_{}.csv'.format(d)\n",
    "result = get_news_list()\n",
    "result.to_csv(file_path, index=False)\n",
    "\n",
    "file_path = r'.\\testfiles\\news\\{}'.format(d)\n",
    "# 폴더가 없으면 생성\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "for title, news in zip(result['title'], result['content']):\n",
    "    # 파일명에 사용할 수 없는 문자를 제거\n",
    "    title = re.sub(r'[\\W]', '', title)\n",
    "    with open(file_path + f'\\{title}.txt', 'wt', encoding='utf-8') as f:\n",
    "        f.write(news)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 증권 주식 등락률 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .\\testfiles\\stock_crawling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .\\testfiles\\stock_crawling.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "\n",
    "base_url = r'https://finance.naver.com/sise/sise_market_sum.naver?&page={}'\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "stock_d = dict()\n",
    "\n",
    "def dict_init():\n",
    "    global stock_d\n",
    "    stock_d = {\n",
    "        'title' : [],\n",
    "        'current price' : [],\n",
    "        'full day fee' : [],\n",
    "        'fluctuation rate' : [],\n",
    "        'face value' : [],\n",
    "        'market cap' : [],\n",
    "        'number of listed shares' : [],\n",
    "        'foreigner ratio' : [],\n",
    "        'trading volume' : [],\n",
    "        'PER' : [],\n",
    "        'ROE' : []\n",
    "    }\n",
    "\n",
    "def get_stock_info(stock : bs):\n",
    "    # global stock_d\n",
    "    # pprint(stock)\n",
    "    title = stock.select_one('td > a.tltle')\n",
    "    # print('이름 : ',title)\n",
    "    if title == None:\n",
    "        return\n",
    "    \n",
    "    title = title.text\n",
    "    # td_num_l = stock.select('td.number')\n",
    "    # pprint(td_num_l)\n",
    "    current_price = stock.select_one('td.number:nth-child(3)').text.strip()\n",
    "    full_day_fee = stock.select_one('td.number:nth-child(4) > span').text.strip()\n",
    "    full_day_fee_ = stock.select_one('td.number:nth-child(4) > img')\n",
    "    if full_day_fee_ != None:\n",
    "        full_day_fee = full_day_fee_['alt'] + full_day_fee\n",
    "    fluctuation_rate = stock.select_one('td.number:nth-child(5) > span').text.strip()\n",
    "    face_value = stock.select_one('td.number:nth-child(6)').text.strip()\n",
    "    number_of_listed_shares = stock.select_one('td.number:nth-child(7)').text.strip()\n",
    "    market_cap = stock.select_one('td.number:nth-child(8)').text.strip()\n",
    "    foreigner_ratio = stock.select_one('td.number:nth-child(9)').text.strip()\n",
    "    trading_volume = stock.select_one('td.number:nth-child(10)').text.strip()\n",
    "    per = stock.select_one('td.number:nth-child(11)').text.strip()\n",
    "    roe = stock.select_one('td.number:nth-child(12)').text.strip()\n",
    "    \n",
    "    stock_d['title'].append(title)\n",
    "    stock_d['current price'].append(current_price)\n",
    "    stock_d['full day fee'].append(full_day_fee)\n",
    "    stock_d['fluctuation rate'].append(fluctuation_rate)\n",
    "    stock_d['face value'].append(face_value)\n",
    "    stock_d['number of listed shares'].append(number_of_listed_shares)\n",
    "    stock_d['market cap'].append(market_cap)\n",
    "    stock_d['foreigner ratio'].append(foreigner_ratio)\n",
    "    stock_d['trading volume'].append(trading_volume)\n",
    "    stock_d['PER'].append(per)\n",
    "    stock_d['ROE'].append(roe)\n",
    "    # print(stock_d)\n",
    "    \n",
    "def get_naver_stock():\n",
    "    dict_init()\n",
    "    for i in range(1,42):\n",
    "        url = base_url.format(i)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            # pprint(url)\n",
    "            soup = bs(response.text, 'lxml')\n",
    "            try:\n",
    "                # table.type_2 > tbody > tr\n",
    "                # #contentarea > div.box_type_l > table.type_2 > tbody > tr:nth-child(2)\n",
    "                # #contentarea > div.box_type_l > table.type_2 > tbody > tr:nth-child(2)\n",
    "                stocks = soup.select('div.box_type_l > table.type_2 > tbody > tr')\n",
    "                for stock in stocks:\n",
    "                    # print(type(stock))\n",
    "                    get_stock_info(stock)\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                pprint(e)\n",
    "                break\n",
    "    \n",
    "    df = pd.DataFrame(stock_d)\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = r'.\\testfiles\\stock'\n",
    "file_name = r'{}\\stock_{}.csv'.format(file_path, d)\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "result = get_naver_stock()\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "d = datetime.now().strftime('%Y-%m-%d') # strftime : 문자열로 변환\n",
    "\n",
    "base_url = r'https://finance.naver.com/sise/sise_market_sum.naver?&page={}'\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "stock_d = dict()\n",
    "\n",
    "def dict_init():\n",
    "    global stock_d\n",
    "    stock_d = {\n",
    "        'title' : [],\n",
    "        'current price' : [],\n",
    "        'full day fee' : [],\n",
    "        'fluctuation rate' : [],\n",
    "        'face value' : [],\n",
    "        'market cap' : [],\n",
    "        'number of listed shares' : [],\n",
    "        'foreigner ratio' : [],\n",
    "        'trading volume' : [],\n",
    "        'PER' : [],\n",
    "        'ROE' : []\n",
    "    }\n",
    "\n",
    "def get_stock_info(stock : bs):\n",
    "    global stock_d\n",
    "    # pprint(stock)\n",
    "    title = stock.select_one('td > a.tltle')\n",
    "    # print('이름 : ',title)\n",
    "    if title == None:\n",
    "        return\n",
    "    \n",
    "    title = title.text\n",
    "    # td_num_l = stock.select('td.number')\n",
    "    # pprint(td_num_l)\n",
    "    \n",
    "    for k, i in zip(stock_d.keys(), range(2,13)):\n",
    "        if i == 2: \n",
    "            stock_d['title'].append(title)\n",
    "            continue\n",
    "        if i == 4:\n",
    "            full_day_fee = stock.select_one('td.number:nth-child(4)').text.strip()\n",
    "            try:\n",
    "                alt = stock.select_one('td.number:nth-child(4) > img')['alt']\n",
    "                if alt == None:\n",
    "                    alt = '상한' if stock.select_one('td.number:nth-child(4) > img')['src'].endswith('ico_up.jpg') else '하한'\n",
    "                stock_d[k].append(alt + full_day_fee)\n",
    "            except:\n",
    "                stock_d[k].append(full_day_fee)\n",
    "            continue\n",
    "        stock_d[k].append(stock.select_one('td.number:nth-child({})'.format(i)).text.strip())\n",
    "        \n",
    "        \n",
    "    # current_price = stock.select_one('td.number:nth-child(3)').text.strip()\n",
    "    # full_day_fee = stock.select_one('td.number:nth-child(4)').text.strip()\n",
    "    # try:\n",
    "    #     alt = stock.select_one('td.number:nth-child(4) > img')['alt']\n",
    "    #     if alt == None:\n",
    "    #         alt = '상한' if stock.select_one('td.number:nth-child(4) > img')['src'].endswith('ico_up.jpg') else '하한'\n",
    "    #     stock_d[k].append(alt + full_day_fee)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # fluctuation_rate = stock.select_one('td.number:nth-child(5)').text.strip()\n",
    "    # face_value = stock.select_one('td.number:nth-child(6)').text.strip()\n",
    "    # number_of_listed_shares = stock.select_one('td.number:nth-child(7)').text.strip()\n",
    "    # market_cap = stock.select_one('td.number:nth-child(8)').text.strip()\n",
    "    # foreigner_ratio = stock.select_one('td.number:nth-child(9)').text.strip()\n",
    "    # trading_volume = stock.select_one('td.number:nth-child(10)').text.strip()\n",
    "    # per = stock.select_one('td.number:nth-child(11)').text.strip()\n",
    "    # roe = stock.select_one('td.number:nth-child(12)').text.strip()\n",
    "    \n",
    "    # stock_d['title'].append(title)\n",
    "    # stock_d['current price'].append(current_price)\n",
    "    # stock_d['full day fee'].append(full_day_fee)\n",
    "    # stock_d['fluctuation rate'].append(fluctuation_rate)\n",
    "    # stock_d['face value'].append(face_value)\n",
    "    # stock_d['number of listed shares'].append(number_of_listed_shares)\n",
    "    # stock_d['market cap'].append(market_cap)\n",
    "    # stock_d['foreigner ratio'].append(foreigner_ratio)\n",
    "    # stock_d['trading volume'].append(trading_volume)\n",
    "    # stock_d['PER'].append(per)\n",
    "    # stock_d['ROE'].append(roe)\n",
    "    # print(stock_d)\n",
    "    \n",
    "def get_naver_stock():\n",
    "    dict_init()\n",
    "    for i in range(1,42):\n",
    "        url = base_url.format(i)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            # pprint(url)\n",
    "            soup = bs(response.text, 'lxml')\n",
    "            try:\n",
    "                # table.type_2 > tbody > tr\n",
    "                # #contentarea > div.box_type_l > table.type_2 > tbody > tr:nth-child(2)\n",
    "                # #contentarea > div.box_type_l > table.type_2 > tbody > tr:nth-child(2)\n",
    "                stocks = soup.select('div.box_type_l > table.type_2 > tbody > tr')\n",
    "                for stock in stocks:\n",
    "                    # print(type(stock))\n",
    "                    get_stock_info(stock)\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                pprint(e)\n",
    "                break\n",
    "            \n",
    "    for k, l in stock_d.items():\n",
    "        print(f'{k} : {len(l)}')\n",
    "    \n",
    "    df = pd.DataFrame(stock_d)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : 2\n",
      "current price : 3\n",
      "full day fee : 4\n",
      "fluctuation rate : 5\n",
      "face value : 6\n",
      "market cap : 7\n",
      "number of listed shares : 8\n",
      "foreigner ratio : 9\n",
      "trading volume : 10\n",
      "PER : 11\n",
      "ROE : 12\n"
     ]
    }
   ],
   "source": [
    "dict_init()\n",
    "for i, k in zip(stock_d.keys(), range(2,13)):\n",
    "    print(f'{i} : {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : 2007\n",
      "current price : 2007\n",
      "full day fee : 2007\n",
      "fluctuation rate : 2007\n",
      "face value : 2007\n",
      "market cap : 2007\n",
      "number of listed shares : 2007\n",
      "foreigner ratio : 2007\n",
      "trading volume : 2007\n",
      "PER : 2007\n",
      "ROE : 2007\n"
     ]
    }
   ],
   "source": [
    "file_path = r'.\\testfiles\\stock'\n",
    "file_name = r'{}\\stock_{}.csv'.format(file_path, d)\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "result = get_naver_stock()\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : 18\n",
      "current price : 2007\n",
      "full day fee : 3660\n",
      "fluctuation rate : 2007\n",
      "face value : 2007\n",
      "market cap : 2007\n",
      "number of listed shares : 2007\n",
      "foreigner ratio : 2007\n",
      "trading volume : 2007\n",
      "PER : 2007\n",
      "ROE : 2007\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m get_naver_stock()\n",
      "Cell \u001b[1;32mIn[84], line 111\u001b[0m, in \u001b[0;36mget_naver_stock\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m k, l \u001b[39min\u001b[39;00m stock_d\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    109\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(l)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(stock_d)\n\u001b[0;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\hyenz\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hyenz\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\hyenz\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\hyenz\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "result = get_naver_stock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>current price</th>\n",
       "      <th>full day fee</th>\n",
       "      <th>fluctuation rate</th>\n",
       "      <th>face value</th>\n",
       "      <th>market cap</th>\n",
       "      <th>number of listed shares</th>\n",
       "      <th>foreigner ratio</th>\n",
       "      <th>trading volume</th>\n",
       "      <th>PER</th>\n",
       "      <th>ROE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>65,600</td>\n",
       "      <td>상승300</td>\n",
       "      <td>+0.46%</td>\n",
       "      <td>100</td>\n",
       "      <td>5,969,783</td>\n",
       "      <td>3,916,177</td>\n",
       "      <td>51.52</td>\n",
       "      <td>14,763,057</td>\n",
       "      <td>8.14</td>\n",
       "      <td>17.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG에너지솔루션</td>\n",
       "      <td>592,000</td>\n",
       "      <td>상승1,000</td>\n",
       "      <td>+0.17%</td>\n",
       "      <td>500</td>\n",
       "      <td>234,000</td>\n",
       "      <td>1,385,280</td>\n",
       "      <td>5.40</td>\n",
       "      <td>245,221</td>\n",
       "      <td>179.12</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SK하이닉스</td>\n",
       "      <td>87,600</td>\n",
       "      <td>하락900</td>\n",
       "      <td>-1.02%</td>\n",
       "      <td>5,000</td>\n",
       "      <td>728,002</td>\n",
       "      <td>637,730</td>\n",
       "      <td>49.54</td>\n",
       "      <td>1,755,311</td>\n",
       "      <td>28.60</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG화학</td>\n",
       "      <td>825,000</td>\n",
       "      <td>상승20,000</td>\n",
       "      <td>+2.48%</td>\n",
       "      <td>5,000</td>\n",
       "      <td>70,592</td>\n",
       "      <td>582,387</td>\n",
       "      <td>48.44</td>\n",
       "      <td>357,812</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>삼성바이오로직스</td>\n",
       "      <td>793,000</td>\n",
       "      <td>하락19,000</td>\n",
       "      <td>-2.34%</td>\n",
       "      <td>2,500</td>\n",
       "      <td>71,174</td>\n",
       "      <td>564,410</td>\n",
       "      <td>10.71</td>\n",
       "      <td>82,991</td>\n",
       "      <td>69.49</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>KBSTAR 모멘텀로우볼</td>\n",
       "      <td>14,075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>QV 블룸버그 2X 천연가스 선물 ETN(H)</td>\n",
       "      <td>1,400</td>\n",
       "      <td>상승65</td>\n",
       "      <td>+4.87%</td>\n",
       "      <td>0</td>\n",
       "      <td>1,500</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25,101</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>ARIRANG TDF2030액티브</td>\n",
       "      <td>10,410</td>\n",
       "      <td>상승10</td>\n",
       "      <td>+0.10%</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2,101</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>KBSTAR 모멘텀밸류</td>\n",
       "      <td>13,730</td>\n",
       "      <td>상승35</td>\n",
       "      <td>+0.26%</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>ARIRANG TDF2050액티브</td>\n",
       "      <td>10,500</td>\n",
       "      <td>상승25</td>\n",
       "      <td>+0.24%</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>208</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2007 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title current price full day fee fluctuation rate  \\\n",
       "0                          삼성전자        65,600        상승300           +0.46%   \n",
       "1                      LG에너지솔루션       592,000      상승1,000           +0.17%   \n",
       "2                        SK하이닉스        87,600        하락900           -1.02%   \n",
       "3                          LG화학       825,000     상승20,000           +2.48%   \n",
       "4                      삼성바이오로직스       793,000     하락19,000           -2.34%   \n",
       "...                         ...           ...          ...              ...   \n",
       "2002              KBSTAR 모멘텀로우볼        14,075            0            0.00%   \n",
       "2003  QV 블룸버그 2X 천연가스 선물 ETN(H)         1,400         상승65           +4.87%   \n",
       "2004         ARIRANG TDF2030액티브        10,410         상승10           +0.10%   \n",
       "2005               KBSTAR 모멘텀밸류        13,730         상승35           +0.26%   \n",
       "2006         ARIRANG TDF2050액티브        10,500         상승25           +0.24%   \n",
       "\n",
       "     face value market cap number of listed shares foreigner ratio  \\\n",
       "0           100  5,969,783               3,916,177           51.52   \n",
       "1           500    234,000               1,385,280            5.40   \n",
       "2         5,000    728,002                 637,730           49.54   \n",
       "3         5,000     70,592                 582,387           48.44   \n",
       "4         2,500     71,174                 564,410           10.71   \n",
       "...         ...        ...                     ...             ...   \n",
       "2002          0        150                      21            0.00   \n",
       "2003          0      1,500                      21            0.00   \n",
       "2004          0        200                      21            0.00   \n",
       "2005          0        150                      21            0.00   \n",
       "2006          0        180                      19            0.00   \n",
       "\n",
       "     trading volume     PER    ROE  \n",
       "0        14,763,057    8.14  17.07  \n",
       "1           245,221  179.12   5.75  \n",
       "2         1,755,311   28.60   3.56  \n",
       "3           357,812   35.00   6.95  \n",
       "4            82,991   69.49  11.42  \n",
       "...             ...     ...    ...  \n",
       "2002              6     N/A    N/A  \n",
       "2003         25,101     N/A    N/A  \n",
       "2004          2,101     N/A    N/A  \n",
       "2005             24     N/A    N/A  \n",
       "2006            208     N/A    N/A  \n",
       "\n",
       "[2007 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
